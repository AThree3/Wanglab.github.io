<!DOCTYPE html>

<html>

{% include head.html %}

<body style="background-color: rgb(251,251,251);">

  {% include navbar.html %}


    <div style="margin-top:100px" id="publication">
    <div class="container">
        <div class="row">
            <div class="col-md-12">
                <ul class="label nav nav-tabs nav-fill" style="margin-bottom: 20px;">
                  
                    <li role="presentation" class="nav-items" id="All">
                      <a class="nav-link active" href="#5" id="5"><span style="margin-left: 20px;margin-right: 20px;font-size: 22px;">All</span></a>
                    </li>
                    <li role="presentation" class="nav-items" id="Conference">
                        <a class="nav-link" href="#1" id="1"><span style="margin-left: 10px;margin-right: 10px;font-size: 22px;">Conference Papers</span></a>
                    </li>
                    <li role="presentation" class="nav-items" id="Journal">
                        <a class="nav-link " href="#2" id="2"><span style="margin-left: 10px;margin-right: 10px;font-size: 22px;">Journal and Magazine</span></a>
                    </li>
                    <li role="presentation" class="nav-items" id="Poster">
                        <a class="nav-link " href="#3" id="3"><span style="margin-left: 10px;margin-right: 10px;font-size: 22px;">Poster and Preprints</span></a>
                    </li>
                    <li role="presentation" class="nav-items" id="Book">
                        <a class="nav-link " href="#4" id="4"><span style="margin-left: 10px;margin-right: 10px;font-size: 22px;">Book Chapters</span></a>
                    </li>
                </ul>

                <form id="publications-form">
                    <div class="row no-gutters hidden-sm hidden-xs">
                      <div class="col-auto"><select id="select-year" class="form-control">
                          <option value="Year">Year</option>
                          <option class="year" value="All">All</option>
                          <option class="year" value="2023">2023</option>
                          <option class="year" value="2022">2022</option>
                          <option class="year" value="2021">2021</option>
                          <option class="year" value="2020">2020</option>
                          <option class="year" value="2019">2019</option>
                          <option class="year" value="before">Before 2018</option>
                        </select></div>
                      <div class="col-auto pl-2"><select id="select-topic" class="form-control">
                          <option value="Topic">Topic</option>
                          <option class="topic" value="All">All</option>
                          <option class="topic" value="WiFi">WiFi Signals</option>
                          <option class="topic" value="Wearables">Wearables</option>
                          <option class="topic" value="Acoustic">Acoustic Signals</option>
                          <option class="topic" value="Mobile">Mobile Computing</option>
                          <option class="topic" value="mmWave">mmWave</option>
                          <option class="topic" value="RFID">RFID</option>
                          <option class="topic" value="Others">Others</option>
                        </select></div>
                        <div class="col-auto pl-2"><a class="btn btn-light btn-block" onclick="submit()" style="font-weight:500 ">Submit</a></div>
                      <div class="col-auto pl-1"><a class="btn btn-light btn-block" onclick="resetFilters()" style="font-weight:500 ;">Reset filters</a></div>
                    </div>
                  </form>

<!--publication-->
<div class="pub-list">
    <div class="publications">
        <div class="publication card odd" id="b-1">
          
        <div class="row no-gutters">
          <div class="col-auto d-none d-md-block p-2">
            <a href="{{ site.baseurl }}/img/publications/b-1.jpg">
            <img class="thumb" src="{{ site.baseurl }}/img/publications/b-1.jpg" loading="lazy" /></a>
          </div>
          <div class="col pl-2">
            <div class="card-block py-2">
              <div class="bib"><div class="pub-p"><button class="btn" disabled="disabled" style="background-color:rgb(136, 7, 35);color: azure;font-family:'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;">IEEE INFOCOM 2023</button>&nbsp Hongbo Liu, Yan Wang, Jian Liu, Yingying Chen,</div> <em><a href="https://link.springer.com/chapter/10.1007/978-3-030-10597-6_9" target="_blank">Proactive User Authentication Using WiFi Signals in Dynamic Networks,</a></em><div class="pub-p">Proactive and Dynamic Network Defense, Cliff Wang and Zhuo Lu (Eds.), Springer, 2019.  </div></div>
            </div>
          </div>
          <div class="col-auto d-none d-md-block">
            <div class="btn-group-vertical" role="group">
              <a class="btn btn-link p-1" href="#" data-toggle="modal" data-target="#b-1-fulltext">
              <svg xmlns="http://www.w3.org/2000/svg" height="24" viewBox="0 0 24 24" width="24" fill="currentColor"><path d="M0 0h24v24H0z" fill="none"/><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76 0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76 0 5-2.24 5-5s-2.24-5-5-5z"/></svg></a>
              <a class="btn btn-link p-1" href="#" data-toggle="modal" data-target="#b-1-abstract">
              <svg xmlns="http://www.w3.org/2000/svg" height="24" viewBox="0 0 24 24" width="24" fill="currentColor"><path d="M0 0h24v24H0z" fill="none"/><path d="M14 17H4v2h10v-2zm6-8H4v2h16V9zM4 15h16v-2H4v2zM4 5v2h16V5H4z"/></svg></a>
              <a class="btn btn-link p-1" href="#" data-toggle="modal" data-target="#b-1-bibtex">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" width="18px" height="18px"><path d="M0 0h24v24H0z" fill="none"/><path d="M6 17h3l2-4V7H5v6h3zm8 0h3l2-4V7h-6v6h3z"/></svg></a>
            </div>
          </div>
        </div>
        </div>
    </div>

    <div class="modal" id="b-1-fulltext" tabindex="-1" data-focus="false">
        <div class="modal-dialog modal-lg">
          <div class="modal-content">
            <div class="modal-header">
              <h5 class="modal-title">Fulltext Options</h5>
              <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                <span aria-hidden="true">&times;</span>
              </button>
            </div>
            <div class="modal-body">
              <div class="list-group list-group-flush"><a class="list-group-item list-group-item-action pub-toast" href="https://link.springer.com/chapter/10.1007/978-3-030-10597-6_9" target="_blank">https://link.springer.com/chapter/10.1007/</a></div>
            </div>
            <div class="modal-footer">
              <button type="button" class="btn btn-secondary" data-dismiss="modal">Close</button>
            </div>
          </div>
        </div>
      </div>

    <div class="modal" id="b-1-abstract" tabindex="-1" data-focus="false">
        <div class="modal-dialog modal-lg">
          <div class="modal-content">
            <div class="modal-header">
              <h5 class="modal-title">Proactive User Authentication Using WiFi Signals in Dynamic Networks</h5>
              <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                <span aria-hidden="true">&times;</span>
              </button>
            </div>
            <div class="modal-body pub-toast">
                User authentication is the critical first step of network security to detect identity-based attacks
                and prevent subsequent malicious attacks. However, the increasingly dynamic mobile
                environments make it harder to always apply the cryptographic-based methods for user
                authentication due to their infrastructural and key management overhead. Exploiting non-
                cryptographic-based techniques grounded on physical layer properties to perform user
                authentication appears promising. To ensure the security of mobile devices in dynamic …
            </div>
            <div class="modal-footer">
              <button type="button" class="btn btn-secondary" data-dismiss="modal">Close</button>
            </div>
          </div>
        </div>
      </div>
        <div class="modal" id="b-1-bibtex" tabindex="-1" data-focus="false">
        <div class="modal-dialog modal-lg">
          <div class="modal-content">
            <div class="modal-header">
              <h5 class="modal-title">BibTeX Entry</h5>
              <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                <span aria-hidden="true">&times;</span>
              </button>
            </div>
            <div class="modal-body pub-toast">
              <pre>@incollection{liu2019proactive,
                title={Proactive User Authentication Using WiFi Signals in Dynamic Networks},
                author={Liu, Hongbo and Wang, Yan and Liu, Jian and Chen, Yingying},
                booktitle={Proactive and Dynamic Network Defense},
                pages={223--248},
                year={2019},
                publisher={Springer}
              }</pre>
            </div>
            <div class="modal-footer">
              <button type="button" class="btn btn-secondary" data-dismiss="modal">Close</button>
            </div>
          </div>
        </div>
    </div>

      
<!--publication-->
    <div class="publications">
        <div class="publication card even" id="p-1">
        <div class="row no-gutters">
          <div class="col-auto d-none d-md-block p-2">
            <img class="thumb" src="{{ site.baseurl }}/img/publications/infocom.png" loading="lazy" />
          </div>
          <div class="col pl-2">
            <div class="card-block py-2">
              <div class="bib"><div class="pub-p">Yucheng Xie, Ruizhe Jiang, Xiaonan Guo, Yan Wang, Jerry Cheng, Yingying Chen,</div> <em><a href="https://dl.acm.org/doi/abs/10.1145/3498361.3538774?casa_token=yX64w_ZrN_IAAAAA:scSdU4dOWrSSX1f1cokPHDvgWbQ4VM96R0jEGRN9FSDSv2EEnkBozfNKdC_8pIBbNj4BiFA3wywA" target="_blank">Universal Targeted Adversarial Attacks Against mmWave-based Human Activity Recognition,</a></em><div class="pub-p">Proceedings of IEEE International Conference on Computer Communications.</div></div>
            </div>
          </div>
          <div class="col-auto d-none d-md-block">
            <div class="btn-group-vertical" role="group">
              <a class="btn btn-link p-1" href="#" data-toggle="modal" data-target="#p-1-fulltext">
              <svg xmlns="http://www.w3.org/2000/svg" height="24" viewBox="0 0 24 24" width="24" fill="currentColor"><path d="M0 0h24v24H0z" fill="none"/><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76 0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76 0 5-2.24 5-5s-2.24-5-5-5z"/></svg></a>
              <a class="btn btn-link p-1" href="#" data-toggle="modal" data-target="#p-1-abstract">
              <svg xmlns="http://www.w3.org/2000/svg" height="24" viewBox="0 0 24 24" width="24" fill="currentColor"><path d="M0 0h24v24H0z" fill="none"/><path d="M14 17H4v2h10v-2zm6-8H4v2h16V9zM4 15h16v-2H4v2zM4 5v2h16V5H4z"/></svg></a>
              <a class="btn btn-link p-1" href="#" data-toggle="modal" data-target="#p-1-bibtex">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" width="18px" height="18px"><path d="M0 0h24v24H0z" fill="none"/><path d="M6 17h3l2-4V7H5v6h3zm8 0h3l2-4V7h-6v6h3z"/></svg></a>
            </div>
          </div>
        </div>
        </div>
    </div>

    <div class="modal" id="p-1-fulltext" tabindex="-1" data-focus="false">
        <div class="modal-dialog modal-lg">
          <div class="modal-content">
            <div class="modal-header">
              <h5 class="modal-title">Fulltext Options</h5>
              <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                <span aria-hidden="true">&times;</span>
              </button>
            </div>
            <div class="modal-body">
              <div class="list-group list-group-flush"><a class="list-group-item list-group-item-action pub-toast" href="https://dl.acm.org/doi/abs/10.1145/3498361.3538774?casa_token=yX64w_ZrN_IAAAAA:scSdU4dOWrSSX1f1cokPHDvgWbQ4VM96R0jEGRN9FSDSv2EEnkBozfNKdC_8pIBbNj4BiFA3wywA" target="_blank">https://dl.acm.org/doi/abs/10.1145</a></div>
            </div>
            <div class="modal-footer">
              <button type="button" class="btn btn-secondary" data-dismiss="modal">Close</button>
            </div>
          </div>
        </div>
      </div>

    <div class="modal" id="p-1-abstract" tabindex="-1" data-focus="false">
        <div class="modal-dialog modal-lg">
          <div class="modal-content">
            <div class="modal-header">
              <h5 class="modal-title">Universal targeted attacks against mmWave-based human activity recognition system</h5>
              <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                <span aria-hidden="true">&times;</span>
              </button>
            </div>
            <div class="modal-body pub-toast">
                Millimeter wave (mmWave)-based human activity recognition (HAR) systems have emerged in recent years due to their better privacy preservation and higher-resolution sensing. However, these systems are vulnerable to adversarial attacks. In this work, we propose a universal targeted attack method for mmWave-based HAR system. In particular, a universal perturbation is generated in advance which can be added to new-coming mmWave data to deceive the HAR system, causing it to output our desired label. We validate our proposed attack using a public mmWave dataset. We demonstrate the effectiveness of our proposed universal attack with a high attack success rate of over 95%.
            </div>
            <div class="modal-footer">
              <button type="button" class="btn btn-secondary" data-dismiss="modal">Close</button>
            </div>
          </div>
        </div>
      </div>
        <div class="modal" id="p-1-bibtex" tabindex="-1" data-focus="false">
        <div class="modal-dialog modal-lg">
          <div class="modal-content">
            <div class="modal-header">
              <h5 class="modal-title">BibTeX Entry</h5>
              <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                <span aria-hidden="true">&times;</span>
              </button>
            </div>
            <div class="modal-body pub-toast">
              <pre>@inproceedings{xie2022universal,<br>                title={Universal targeted attacks against mmWave-based human activity recognition system},
                author={Xie, Yucheng and Jiang, Ruizhe and Guo, Xiaonan and Wang, Yan and Cheng, Jerry and Chen, Yingying},
                booktitle={Proceedings of the 20th Annual International Conference on Mobile Systems, Applications and Services},
                pages={541--542},
                year={2022}
              }</pre>
            </div>
            <div class="modal-footer">
              <button type="button" class="btn btn-secondary" data-dismiss="modal">Close</button>
            </div>
          </div>
        </div>
      </div>
      
  </div>



<br>
</div>
</div>
</div>
</div>


<!-- <script>
$(function(){
    $(".nav-items li").click(function() {
        $(this).siblings('li').removeClass('active');  // 删除其他兄弟元素的样式
        $(this).addClass('active');                            // 添加当前元素的样式
    });
});

function gotopdf(){
            if($(".nav-items li:first").hasClass("active"))
{
window.location.href="/hydt/index.jhtml";
//有class active执行。。。
}
else{
window.location.href="/tpxw/index.jhtml";
//没有有class active执行。。。
}
        };
</script> -->

<div class="top-to-page" id="top-page">
    <a href="#top" class="scroll"> <i class="fa fa-arrow-circle-up" style="font-size:48px;color:red"></i></a>   
</div>


<script>
  var arr=[{label:"Book",year:"2019",topic:"WiFi",photo:"{{ site.baseurl }}/img/publications/b-1.jpg",pubname:"Book Chapters",authors:"Hongbo Liu, Yan Wang, Jian Liu, Yingying Chen",src:"https://link.springer.com/chapter/10.1007/978-3-030-10597-6_9",name:"Proactive User Authentication Using WiFi Signals in Dynamic Networks",public:"Proactive and Dynamic Network Defense, Cliff Wang and Zhuo Lu (Eds.), Springer, 2019",acceptance:"",introduction:"User authentication is the critical first step of network security to detect identity-based attacks and prevent subsequent malicious attacks. However, the increasingly dynamic mobile environments make it harder to always apply the cryptographic-based methods for user authentication due to their infrastructural and key management overhead. Exploiting non- cryptographic-based techniques grounded on physical layer properties to perform user authentication appears promising. To ensure the security of mobile devices in dynamic …",class:"article{Liu2019ProactiveUA,<br>  title={Proactive User Authentication Using WiFi Signals in Dynamic Networks},<br>  author={Hongbo Liu and Yan Wang and Jian Liu and Yingying Chen},<br>  journal={Proactive and Dynamic Network Defense},<br>  year={2019}<br>}"},{label:"Conference",year:"2023",topic:"mmWave",photo:"{{ site.baseurl }}/img/publications/infocom.png",pubname:"IEEE INFOCOM 2023",authors:"Yucheng Xie, Ruizhe Jiang, Xiaonan Guo, Yan Wang, Jerry Cheng, Yingying Chen",src:"https://arxiv.org/abs/2101.05639",name:"Universal Targeted Adversarial Attacks Against mmWave-based Human Activity Recognition",public:"Proceedings of IEEE International Conference on Computer Communications",acceptance:"(Acceptance rate: 252/1312 = 19.2%)",introduction:"Millimeter wave (mmWave)-based human activity recognition (HAR) systems have emerged in recent years due to their better privacy preservation and higher-resolution sensing. However, these systems are vulnerable to adversarial attacks. In this work, we propose a universal targeted attack method for mmWave-based HAR system. In particular, a universal perturbation is generated in advance which can be added to new-coming mmWave data to deceive the HAR system, causing it to output our desired label. We validate our proposed attack using a public mmWave dataset. We demonstrate the effectiveness of our proposed universal attack with a high attack success rate of over 95%.",class:"inproceedings{xie2022universal,<br>  title={Universal targeted attacks against mmWave-based human activity recognition system},<br>  author={Xie, Yucheng and Jiang, Ruizhe and Guo, Xiaonan and Wang, Yan and Cheng, Jerry and Chen, Yingying},<br>  booktitle={Proceedings of the 20th Annual International Conference on Mobile Systems, Applications and Services},<br>  pages={541--542},<br>  year={2022}<br>}"},{label:"Conference",year:"2023",topic:"Mobile",photo:"{{ site.baseurl }}/img/publications/asiaccs.png",pubname:"ACM ASIACCS 2023",authors:"Bin Hu, Yan Wang, Jerry Cheng, Tianming Zhao, Yucheng Xie, Xiaonan Guo, Yingying Chen",src:"",name:"Secure and Efficient Mobile DNN Execution Using Trusted Execution Environments",public:"Proceedings of the ACM ASIA Conference on Computer and Communications Security",acceptance:"(Acceptance rate: 35/204 = 17%)",introduction:"",class:""},{label:"Conference",year:"2022",topic:"WiFi",photo:"{{ site.baseurl }}/img/publications/sensys.png",pubname:"ACM SenSys 2022",authors:"Kailong Wang, Cong Shi, Jerry Cheng, Yan Wang, Minge Xie, Yingying Chen",src:"",name:"Solving the WiFi Sensing Dilemma in Reality Leveraging Conformal Prediction",public:"Proceedings of the ACM Conference on Embedded Networked Sensor Systems ",acceptance:"",introduction:"",class:""},{label:"Conference",year:"2022",topic:"RFID",photo:"{{ site.baseurl }}/img/publications/mobihoc.png",pubname:"ACM Mobihoc 2022",authors:"Bin Hu, Tianming Zhao, Yan Wang, Jerry Cheng, Richard Howard, Yingying Chen, Hao Wan",src:"https://dl.acm.org/doi/10.1145/3492866.3549718",name:"BioTag: Robust RFID-based Continuous User Verification Using Physiological Features from Respiration",public:"Proceedings of the International Symposium on Theory, Algorithmic Foundations, and Protocol Design for Mobile Networks and Mobile Computing",acceptance:"(Acceptance rate: 24/121 = 19.8%)",introduction:"For decades, one-time verification has been the standard for user verification at entry points, office rooms, etc. However, such approaches request users to provide their secrets (e.g., entering passwords and collecting fingerprints) and re-verify (e.g., screen shutdown) manually. Thus, they cannot confirm whether the user is a legitimate or an imposter after verification, which raises the urgent demand for a more convenient and secure solution to perform continuous user verification. However, existing continuous verification methods heavily rely on users' active participation, which is inconvenient. Toward this end, we propose a continuous user verification system, BioTag, which utilizes the low-cost radio frequency identification (RFID) technology to capture unique physiological characteristics rooted in the users' respiration motions for continuous user verification. Specifically, we use two RFID tags attached to a user's chest and abdomen to capture the user's intrinsic respiratory patterns via RFID signals. We develop respiratory feature extraction methods based on waveform morphology analysis and fuzzy wavelet transformation (FWPT) to derive unique biometric information from the user's respiration signals. Furthermore, we develop an adaptive classifier using the gradient boosting decision tree (GBDT) to identify legitimate users and attackers accurately. Extensive experiments involving 41 participants demonstrate that BioTag can robustly authenticate users and detect various types of adversaries with low training effort. In particular, our system can achieve over 95.2% and 94.8% verification accuracy on random attack and imitation attack scenarios, respectively.",class:"inproceedings{hu2022biotag,<br>  title={BioTag: robust RFID-based continuous user verification using physiological features from respiration},<br>  author={Hu, Bin and Zhao, Tianming and Wang, Yan and Cheng, Jerry and Howard, Richard and Chen, Yingying and Wan, Hao},<br>  booktitle={Proceedings of the Twenty-Third International Symposium on Theory, Algorithmic Foundations, and Protocol Design for Mobile Networks and Mobile Computing},<br>  pages={191--200},<br>  year={2022}<br>}"},{label:"Conference",year:"2022",topic:"Others",photo:"{{ site.baseurl }}/img/publications/eccv.png",pubname:"Springer ECCV 2022",authors:"Huy Phan, Cong Shi, Yi Xie, Tianfang Zhang, Zhuohang Li, Tianming Zhao, Jian Liu, Yan Wang, Yingying Chen, Bo Yuan",src:"https://arxiv.org/abs/2208.10608",name:"RIBAC: Towards Robust and Imperceptible Backdoor Attack against Compact DNN",public:"European Conference on Computer Vision",acceptance:"",introduction:"Recently backdoor attack has become an emerging threat to the security of deep neural network (DNN) models. To date, most of the existing studies focus on backdoor attack against the uncompressed model; while the vulnerability of compressed DNNs, which are widely used in the practical applications, is little exploited yet. In this paper, we propose to study and develop Robust and Imperceptible Backdoor Attack against Compact DNN models (RIBAC). By performing systematic analysis and exploration on the important design knobs, we propose a framework that can learn the proper trigger patterns, model parameters and pruning masks in an efficient way. Thereby achieving high trigger stealthiness, high attack success rate and high model efficiency simultaneously. Extensive evaluations across different datasets, including the test against the state-of-the-art defense mechanisms, demonstrate the high robustness, stealthiness and model efficiency of RIBAC. Code is available at https://github.com/huyvnphan/ECCV2022-RIBAC.",class:"inproceedings{phan2022ribac,<br>  title={RIBAC: Towards Robust and Imperceptible Backdoor Attack against Compact DNN},<br>  author={Phan, Huy and Shi, Cong and Xie, Yi and Zhang, Tianfang and Li, Zhuohang and Zhao, Tianming and Liu, Jian and Wang, Yan and Chen, Yingying and Yuan, Bo},<br>  booktitle={European Conference on Computer Vision},<br>  pages={708--724},<br>  year={2022},<br>  organization={Springer}<br>}"},{label:"Conference",year:"2022",topic:"Others",photo:"{{ site.baseurl }}/img/publications/mobicom.png",pubname:"ACM Mobicom 2022",authors:"Cong Shi, Tianfang Zhang, Zhuohang Li, Huy Phan, Tianming Zhao, Yan Wang, Jian Liu, Bo Yuan, Yingying Chen",src:"https://dl.acm.org/doi/abs/10.1145/3495243.3560531",name:"Audio-domain Position-independent Backdoor Attack via Subsecond Triggers",public:"Proceedings of the 28th Annual International Conference On Mobile Computing And Networking",acceptance:"(Acceptance rate: 56/314 = 17.8%)",introduction:"Deep learning models have become key enablers of voice user interfaces. With the growing trend of adopting outsourced training of these models, backdoor attacks, stealthy yet effective training-phase attacks, have gained increasing attention. They inject hidden trigger patterns through training set poisoning and overwrite the model's predictions in the inference phase. Research in backdoor attacks has been focusing on image classification tasks, while there have been few studies in the audio domain. In this work, we explore the severity of audio-domain backdoor attacks and demonstrate their feasibility under practical scenarios of voice user interfaces, where an adversary injects (plays) an unnoticeable audio trigger into live speech to launch the attack. To realize such attacks, we consider jointly optimizing the audio trigger and the target model in the training phase, deriving a position-independent, unnoticeable, and robust audio trigger. We design new data poisoning techniques and penalty-based algorithms that inject the trigger into randomly generated temporal positions in the audio input during training, rendering the trigger resilient to any temporal position variations. We further design an environmental sound mimicking technique to make the trigger resemble unnoticeable situational sounds and simulate played over-the-air distortions to improve the trigger's robustness during the joint optimization process. Extensive experiments on two important applications (i.e., speech command recognition and speaker recognition) demonstrate that our attack can achieve an average success rate of over 99% under both digital and physical attack settings.",class:"inproceedings{shi2022audio,<br>  title={Audio-domain position-independent backdoor attack via unnoticeable triggers},<br>  author={Shi, Cong and Zhang, Tianfang and Li, Zhuohang and Phan, Huy and Zhao, Tianming and Wang, Yan and Liu, Jian and Yuan, Bo and Chen, Yingying},<br>  booktitle={Proceedings of the 28th Annual International Conference on Mobile Computing And Networking},<br>  pages={583--595},<br>  year={2022}<br>}"},{label:"Conference",year:"2022",topic:"ICCCN",photo:"{{ site.baseurl }}/img/publications/ICCCN.jpg",pubname:"ICCCN 2022",authors:"Yucheng Xie, Ruizhe Jiang, Xiaonan Guo, Yan Wang, Jerry Cheng and Yingying Chen",src:"https://ieeexplore.ieee.org/document/9868878",name:"mmFit: Low-Effort Personalized Fitness Monitoring Using Millimeter Wave",public:"The International Conference on Computer Communications and Networks (ICCCN 2022) ",acceptance:"",introduction:"There is a growing trend for people to perform work-outs at home due to the global pandemic of COVID-19 and the stay-at-home policy of many countries. Since a self-designed fitness plan often lacks professional guidance to achieve ideal outcomes, it is important to have an in-home fitness monitoring system that can track the exercise process of users. Traditional camera-based fitness monitoring may raise serious privacy concerns, while sensor-based methods require users to wear dedicated devices. Recently, researchers propose to utilize RF signals to enable non-intrusive fitness monitoring, but these approaches all require huge training efforts from users to achieve a satisfactory performance, especially when the system is used by multiple users (e.g., family members). In this work, we design and implement a fitness monitoring system using a single COTS mm Wave device. The proposed system integrates workout recognition, user identification, multi-user monitoring, and training effort reduction modules and makes them work together in a single system. In particular, we develop a domain adaptation framework to reduce the amount of training data collected from different domains via mitigating impacts caused by domain characteristics embedded in mm Wave signals. We also develop a GAN-assisted method to achieve better user identification and workout recognition when only limited training data from the same domain is available. We propose a unique spatialtemporal heatmap feature to achieve personalized workout recognition and develop a clustering-based method for concurrent workout monitoring. Extensive experiments with 14 typical workouts involving 11 participants demonstrate that our system can achieve 97% average workout recognition accuracy and 91% user identification accuracy.",class:"inproceedings{xie2022mmfit,<br>  title={mmFit: Low-Effort Personalized Fitness Monitoring Using Millimeter Wave},<br>  author={Xie, Yucheng and Jiang, Ruizhe and Guo, Xiaonan and Wang, Yan and Cheng, Jerry and Chen, Yingying},<br>  booktitle={2022 International Conference on Computer Communications and Networks (ICCCN)},<br>  pages={1--10},<br>  year={2022},<br>  organization={IEEE}<br>}"},{label:"Conference",year:"2022",topic:"Acoustic",photo:"{{ site.baseurl }}/img/publications/default.png",pubname:"IEEE ICDCS 2022",authors:"Cong Shi, Tianming Zhao, Wenjin Zhang, Ahmed Tanvir Mahdad, Zhengkun Ye, Yan Wang, Nitesh Saxena and Yingying Chen",src:"https://ieeexplore.ieee.org/abstract/document/9912174",name:"Defending against Thru-barrier Stealthy Voice Attacks via Cross-Domain Sensing on Phoneme Sounds",public:"Proceedings of the 42nd IEEE International Conference on Distributed Computing Systems",acceptance:"(Acceptance rate: 114/573 = 19.9%) ",introduction:"The open nature of voice input makes voice assistant (VA) systems vulnerable to various acoustic attacks (e.g., replay and voice synthesis attacks). A simple yet effective way for adversaries to launch these attacks is to hide behind barriers (e.g., a wall, a window, or a door) and give unauthorized voice commands without being observed by legitimate users. In this work, we develop an automated, training-free defense system that can protect VA systems from such thru-barrier acoustic attacks. Our study finds that acoustic signals passing through the barriers generally present a unique frequency-selective effect in the vibration domain. Thus, we propose to devise a system to capture this unique effect of barriers by leveraging low-cost, cross-domain sensing available in users’ wearables. The system replays the audio-domain signals with the wearable’s speaker and captures the conductive vibrations caused by the audio sounds in the vibration domain via the built-in accelerometer. To improve the proposed system’s reliability, we develop a unique vibration-domain enhancement method to extract the phonemes most sensitive to the frequency-selective effect of barriers. We identify effective vibration-domain features that capture the barriers’ effects in the vibration domain. A 2D-correlation-based method is developed to examine the speech similarity between the recordings from the VA system and the user’s wearable and detect thru-barrier attacks. Extensive experiments with various barriers and environments demonstrate that the proposed defense system can effectively defend random, replay, synthesis, and hidden voice attacks with less than 4% equal error rates.",class:"inproceedings{shi2022defending,<br>  title={Defending against Thru-barrier Stealthy Voice Attacks via Cross-Domain Sensing on Phoneme Sounds},<br>  author={Shi, Cong and Zhao, Tianming and Zhang, Wenjin and Mahdad, Ahmed Tanvir and Ye, Zhengkun and Wang, Yan and Saxena, Nitesh and Chen, Yingying},<br>  booktitle={2022 IEEE 42nd International Conference on Distributed Computing Systems (ICDCS)},<br>  pages={680--690},<br>  year={2022},<br>  organization={IEEE}<br>}"},{label:"Conference",year:"2021",topic:"mmWave",photo:"{{ site.baseurl }}/img/publications/default.png",pubname:"IEEE/ACM CHASE 2021",authors:"Cong Shi, Li Lu, Jian Liu, Yan Wang, Yingying Chen, Jiadi Yu",src:"https://www.sciencedirect.com/science/article/pii/S2352648321000489?casa_token=bplMDQq8-AgAAAAA:6-c1HxOIM_dfbaBRw-4rN6TqyGarwyJ-TKJd81TkinIFtxADC_apV2bOjVW1JuYjablGy3SSLg",name:"mPose: Environment- and Subject-Agnostic 3D Skeleton Posture Reconstruction Leveraging a Single mmWave Device",public:"Elsevier Smart Health, 2021",acceptance:"",introduction:"Human skeleton posture reconstruction is an essential component for human–computer interactions (HCI) in various application domains. Traditional approaches usually rely on either cameras or on-body sensors, which induce privacy concerns or inconvenient practical setups. To address these practical concerns, this paper proposes a low-cost contactless skeleton posture reconstruction system, mPose, which can reconstruct a user’s 3D skeleton postures using a single mmWave device. mPose does not require the user to wear any sensors and can enable a broad range of emerging mobile applications (e.g., VR gaming and pervasive user input) via mmWave-5G ready Internet of Things (IoT) devices. Particularly, the system extracts multi-dimensional spatial information from mmWave signals which characterizes the skeleton postures in a 3D space. To mitigate the impacts of environmental changes, mPose dynamically detects the user location and extracts spatial features from the mmWave signals reflected only from the user. Furthermore, we develop a deep regression method with a domain discriminator to learn a mapping between the spatial features and the joint coordinates of human body while removing subject-specific characteristics, realizing robust posture reconstruction across users. Extensive experiments, involving 17 representative body postures, 7 subjects, and 3 indoor environments, show that mPose outperforms contemporary state-of-the-art RF-based solutions with a lower average joint error of only 30 mm, while achieving transferability across environments and subjects at the same time.",class:"article{shi2022mpose,<br>  title={mPose: Environment-and subject-agnostic 3D skeleton posture reconstruction leveraging a single mmWave device},<br>  author={Shi, Cong and Lu, Li and Liu, Jian and Wang, Yan and Chen, Yingying and Yu, Jiadi},<br>  journal={Smart Health},<br>  volume={23},<br>  pages={100228},<br>  year={2022},<br>  publisher={Elsevier}<br>}"},{label:"Conference",year:"2021",topic:"WiFi",photo:"{{ site.baseurl }}/img/publications/default.png",pubname:"IEEE MASS 2021",authors:"Cong Shi, Tianming Zhao, Yucheng Xie, Tianfang Zhang, Yan Wang, Xiaonan Guo, Yingying Chen",src:"https://ieeexplore.ieee.org/abstract/document/9637801?casa_token=CWfm-o0TDLgAAAAA:EYfMr1tSKWmD-s6rML-Fg1nuFftwDtFPuH5bTP_kP-sC0lxklKtPoa0IFKsF47YumZLImTxGrQ",name:"Environment-independent In-baggage Object Identification Using WiFi Signals",public:"Proceedings of the IEEE International Conference on Mobile Ad-Hoc and Smart Systems ",acceptance:"",introduction:"Low-cost in-baggage object identification is highly demanded in enhancing public safety and smart manufacturing. Existing approaches usually require specialized equipment and heavy deployment overhead, making them hard to scale for wide deployment. The recent WiFi-based approach is unsuitable for practical deployment as it did not address dynamic environmental impacts. In this work, we propose an environment-independent in-baggage object identification system by leveraging low-cost WiFi. We exploit the channel state information (CSI) to capture material and shape characteristics to facilitate fine-grained inbaggage object identification. A major challenge of building such a system is that CSI measurements are sensitive to real-world dynamics, such as different types of baggage, time-varying ambient noises and interferences, and different deployment environments. To tackle these problems, we develop WiFi features based on polarized directional antennas that can capture objects’ material and shape characteristics. A convolutional neural network-based model is developed to constructively integrate the WiFi features and perform accurate in-baggage object identification. We also develop a material-based domain adaptation using adversarial learning to facilitate fast deployments in different environments. We conduct extensive experiments involving 14 representation objects, 4 types of bags in 3 different room environments. The results show that our system can achieve over 97% in the same environment, and our domain adaptation method can improve the object identification accuracy by 42% when the system is deployed in a new environment with little training.",class:"inproceedings{shi2021environment,<br>  title={Environment-independent In-baggage Object Identification Using WiFi Signals},<br>  author={Shi, Cong and Zhao, Tianming and Xie, Yucheng and Zhang, Tianfang and Wang, Yan and Guo, Xiaonan and Chen, Yingying},<br>  booktitle={2021 IEEE 18th International Conference on Mobile Ad Hoc and Smart Systems (MASS)},<br>  pages={71--79},<br>  year={2021},<br>  organization={IEEE}<br>}"},{label:"Conference",year:"2021",topic:"WiFi",photo:"{{ site.baseurl }}/img/publications/default.png",pubname:"IEEE MASS 2021",authors:"Keegan Kresge, Sophia Martino, Tianming Zhao, Yan Wang",src:"https://ieeexplore.ieee.org/abstract/document/9637801?casa_token=IDUrOqbZHBoAAAAA:hQYUjbeo9R90s7qzl-LiXEpIydp1V_-MNnZBwn3zyMKfjViU4J3KrrTQhssDVYwBuYLkqu3Plw",name:"WiFi-based Contactless Gesture Recognition Using Lightweight CNN",public:"Proceedings of the IEEE International Conference on Mobile Ad-Hoc and Smart Systems",acceptance:"",introduction:"Low-cost in-baggage object identification is highly demanded in enhancing public safety and smart manufacturing. Existing approaches usually require specialized equipment and heavy deployment overhead, making them hard to scale for wide deployment. The recent WiFi-based approach is unsuitable for practical deployment as it did not address dynamic environmental impacts. In this work, we propose an environment-independent in-baggage object identification system by leveraging low-cost WiFi. We exploit the channel state information (CSI) to capture material and shape characteristics to facilitate fine-grained inbaggage object identification. A major challenge of building such a system is that CSI measurements are sensitive to real-world dynamics, such as different types of baggage, time-varying ambient noises and interferences, and different deployment environments. To tackle these problems, we develop WiFi features based on polarized directional antennas that can capture objects’ material and shape characteristics. A convolutional neural network-based model is developed to constructively integrate the WiFi features and perform accurate in-baggage object identification. We also develop a material-based domain adaptation using adversarial learning to facilitate fast deployments in different environments. We conduct extensive experiments involving 14 representation objects, 4 types of bags in 3 different room environments. The results show that our system can achieve over 97% in the same environment, and our domain adaptation method can improve the object identification accuracy by 42% when the system is deployed in a new environment with little training.",class:"inproceedings{shi2021environment,<br>  title={Environment-independent In-baggage Object Identification Using WiFi Signals},<br>  author={Shi, Cong and Zhao, Tianming and Xie, Yucheng and Zhang, Tianfang and Wang, Yan and Guo, Xiaonan and Chen, Yingying},<br>  booktitle={2021 IEEE 18th International Conference on Mobile Ad Hoc and Smart Systems (MASS)},<br>  pages={71--79},<br>  year={2021},<br>  organization={IEEE}<br>}"},{label:"Conference",year:"2021",topic:"Others",photo:"{{ site.baseurl }}/img/publications/ijcnn.png",pubname:"IJCNN 2021",authors:"Bin Hu, Tianming Zhao, Yucheng Xie, Yan Wang, Xiaonan Guo, Jerry Cheng, Yingying Chen",src:"https://ieeexplore.ieee.org/abstract/document/9533522?casa_token=vJz8pQmNauEAAAAA:kXxvUo1L1-zPxoN0hQ6dOoXTitKQy4F3lzey7L1ATEk3uzmNoVNNUClmlikZP1s6nBbDi3RXXw",name:"MIXP: Efficient Deep Neural Networks Pruning for Further FLOPs Compression via Neuron Bond",public:"Proceedings of International Joint Conference on Neural Networks",acceptance:"",introduction:"Neuron networks pruning is effective in compressing pre-trained CNNs for their deployment on low-end edge devices. However, few works have focused on reducing the computational cost of pruning and inference. We find that existing pruning methods usually remove parameters without fine-grained impact analysis, making it hard to achieve an optimal solution. This work develops a novel mixture pruning mechanism, MIXP, which can effectively reduce the computational cost of CNNs while maintaining a high weight compression ratio and model accuracy. We propose to remove neuron bond that can effectively reduce convolution computations and weight size in CNNs. We also design an influence factor to analyze the importance of neuron bonds and weights in a fine-grained way so that MIXP could achieve precise pruning with few retraining iterations. Experiments with MNIST, CIFAR-10, and ImageNet datasets demonstrate that MIXP could achieve significantly fewer FLOPs and retraining iterations on four widely-used CNNs than existing pruning methods.",class:"inproceedings{hu2021mixp,<br>  title={MIXP: Efficient Deep Neural Networks Pruning for Further FLOPs Compression via Neuron Bond},<br>  author={Hu, Bin and Zhao, Tianming and Xie, Yucheng and Wang, Yan and Guo, Xiaonan and Cheng, Jerry and Chen, Yingying},<br>  booktitle={2021 International Joint Conference on Neural Networks (IJCNN)},<br>  pages={1--8},<br>  year={2021},<br>  organization={IEEE}<br>}"},{label:"Conference",year:"2021",topic:"Others",photo:"{{ site.baseurl }}/img/publications/infocom.png",pubname:"IEEE INFOCOM 2021",authors:"Hongbo Liu, Yan Wang, Yanzhi Ren, Yingying Chen",src:"https://ieeexplore.ieee.org/abstract/document/9488848?casa_token=7F5ccZxZN94AAAAA:ctceUNQClMIwZpzdj-qzO4SPPZFlylp76hDtRa6CK3FV2GQv7Q2T4EA-HZt3lc1TLf63cqF03g",name:"Bipartite Graph Matching Based Secret Key Generation",public:"Proceedings of IEEE International Conference on Computer Communications",acceptance:"(Acceptance rate: 252/1266 = 19.9%)",introduction:"The physical layer secret key generation exploiting wireless channel reciprocity has attracted considerable attention in the past two decades. On-going research have demonstrated its viability in various radio frequency (RF) systems. Most of existing work rely on quantization technique to convert channel measurements into digital binaries that are suitable for secret key generation. However, non-simultaneous packet exchanges in time division duplex systems and noise effects in practice usually create random channel measurements between two users, leading to inconsistent quantization results and mismatched secret bits. While significant efforts were spent in recent research to mitigate such non-reciprocity, no efficient method has been found yet. Unlike existing quantization-based approaches, we take a different viewpoint and perform the secret key agreement by solving a bipartite graph matching problem. Specifically, an efficient dual-permutation secret key generation method, DP-SKG, is developed to match the randomly permuted channel measurements between a pair of users by minimizing their discrepancy holistically. DP-SKG allows two users to generate the same secret key based on the permutation order of channel measurements despite the non-reciprocity over wireless channels. Extensive experimental results show that DP-SKG could achieve error-free key agreement on received signal strength (RSS) with a low cost under various scenarios.",class:"inproceedings{liu2021bipartite,<br>  title={Bipartite graph matching based secret key generation},<br>  author={Liu, Hongbo and Wang, Yan and Ren, Yanzhi and Chen, Yingying},<br>  booktitle={IEEE INFOCOM 2021-IEEE Conference on Computer Communications},<br>  pages={1--10},<br>  year={2021},<br>  organization={IEEE}<br>}"},{label:"Conference",year:"2020",topic:"Wearables",photo:"{{ site.baseurl }}/img/publications/acsac.png",pubname:"ACSAC 2020",authors:"Cong Shi, Yan Wang, Yingying Chen, Nitesh Saxena, Chen Wang",src:"https://dl.acm.org/doi/abs/10.1145/3427228.3427259",name:"WearID: Low-Effort Wearable-Assisted Authentication of Voice Commands via Cross-Domain Comparison without Training",public:"Proceedings of the 36th Annual Computer Security Applications Conference",acceptance:"",introduction:"Due to the open nature of voice input, voice assistant (VA) systems (e.g., Google Home and Amazon Alexa) are vulnerable to various security and privacy leakages (e.g., credit card numbers, passwords), especially when issuing critical user commands involving large purchases, critical calls, etc. Though the existing VA systems may employ voice features to identify users, they are still vulnerable to various acoustic-based attacks (e.g., impersonation, replay, and hidden command attacks). In this work, we propose a training-free voice authentication system, WearID, leveraging the cross-domain speech similarity between the audio domain and the vibration domain to provide enhanced security to the ever-growing deployment of VA systems. In particular, when a user gives a critical command, WearID exploits motion sensors on the user’s wearable device to capture the aerial speech in the vibration domain and verify it with the speech captured in the audio domain via the VA device’s microphone. Compared to existing approaches, our solution is low-effort and privacy-preserving, as it neither requires users’ active inputs (e.g., replying messages/calls) nor to store users’ privacy-sensitive voice samples for training. In addition, our solution exploits the distinct vibration sensing interface and its short sensing range to sound (e.g., 25cm) to verify voice commands. Examining the similarity of the two domains’ data is not trivial. The huge sampling rate gap (e.g., 8000Hz vs. 200Hz) between the audio and vibration domains makes it hard to compare the two domains’ data directly, and even tiny data noises could be magnified and cause authentication failures. To address the challenges, we investigate the complex relationship between the two sensing domains and develop a spectrogram-based algorithm to convert the microphone data into the lower-frequency “ motion sensor data” to facilitate cross-domain comparisons. We further develop a user authentication scheme to verify that the received voice command originates from the legitimate user based on the cross-domain speech similarity of the received voice commands. We report on extensive experiments to evaluate the WearID under various audible and inaudible attacks. The results show WearID can verify voice commands with 99.8% accuracy in the normal situation and detect 97.2% fake voice commands from various attacks, including impersonation/replay attacks and hidden voice/ultrasound attacks.",class:"inproceedings{shi2020wearid,<br>  title={WearID: Low-Effort Wearable-Assisted Authentication of Voice Commands via Cross-Domain Comparison without Training},<br>  author={Shi, Cong and Wang, Yan and Chen, Yingying and Saxena, Nitesh and Wang, Chen},<br>  booktitle={Annual Computer Security Applications Conference},<br>  pages={829--842},<br>  year={2020}<br>}"},{label:"Conference",year:"2020",topic:"Mobile",photo:"{{ site.baseurl }}/img/publications/asiaccs.png",pubname:"ACM ASIACCS 2020",authors:"Yilin Yang, Yan Wang, Yingying Chen, Chen Wang",src:"https://dl.acm.org/doi/abs/10.1145/3320269.3384741",name:"EchoLock: Towards Low-effort Mobile User Identification Leveraging Structure-borne Echos",public:"Proceedings of the ACM ASIA Conference on Computer and Communications Security",acceptance:"(Acceptance rate: 67/308=21.8%)",introduction:"Many existing identification approaches require active user input, specialized sensing hardware, or personally identifiable information such as fingerprints or face scans. In this paper, we propose EchoLock, a low-effort identification scheme that validates the user by sensing hand geometry via commodity microphones and speakers. EchoLock can serve as a complementary verification method for high-end devices or as a stand-alone user identification scheme for lower-end devices without using privacy-sensitive features. In addition to security applications, our system can also personalize user interactions with smart devices, such as automatically adapting settings or preferences when different people are holding smart remotes. To this end, we study the impact of hands on structure borne sound propagation in mobile devices and develop a user identification scheme that can measure, quantify, and exploit distinct sound reflections in order to differentiate distinct identities. Particularly, we propose a non-intrusive hand sensing technique to derive unique acoustic features in both time and frequency domain, which can effectively capture the physiological and behavioral traits of a user's hand (e.g., hand contours, finger sizes, holding strengths, and holding styles). Furthermore, learning-based algorithms are developed to robustly identify the user under various environments and conditions. We conduct extensive experiments with 20 participants, gathering 80,000 hand geometry samples using different hardware setups across 160 key use case scenarios. Our results show that EchoLock is capable of identifying users with over 94% accuracy, without requiring any active user input.",class:"inproceedings{yang2020echolock,<br>  title={Echolock: Towards low-effort mobile user identification leveraging structure-borne echos},<br>  author={Yang, Yilin and Wang, Yan and Chen, Yingying and Wang, Chen},<br>  booktitle={Proceedings of the 15th ACM Asia Conference on Computer and Communications Security},<br>  pages={772--783},<br>  year={2020}<br>}"},{label:"Conference",year:"2020",topic:"Acoustic",photo:"{{ site.baseurl }}/img/publications/ubicomp.png",pubname:"ACM UbiComp 2020",authors:"Li Lu, Jiadi Yu, Yingying Chen, Yan Wang, Yanmin Zhu",src:"https://dl.acm.org/doi/abs/10.1145/3397320?casa_token=dlstsHYc7JsAAAAA:2SVY1nxAMasXa55YXOewX18pwow-OXEhD-zuoQjLwSeiprIeR7-zmcbLOX4rS2t5anGTLXIUfOmi",name:"VocalLock: Sensing Vocal Tract for Passphrase-Independent User Authentication Leveraging Acoustic Signals on Smartphones",public:"Proceedings of ACM International Joint Conference on Pervasive and Ubiquitous Computing ",acceptance:"",introduction:"Recent years have witnessed the surge of biometric-based user authentication for mobile devices due to its promising security and convenience. As a natural and widely-existed behavior, human speaking has been exploited for user authentication. Existing voice-based user authentication explores the unique characteristics from either the voiceprint or mouth movements, which is vulnerable to replay attacks and mimic attacks. During speaking, the vocal tract, including the static shape and dynamic movements, also exhibits the individual uniqueness, and they are hardly eavesdropped and imitated by adversaries. Hence, our work aims to employ the individual uniqueness of vocal tract to realize user authentication on mobile devices. Moreover, most voice-based user authentications are passphrase-dependent, which significantly degrade the user experience. Thus, such user authentications are pressed to be implemented in a passphrase-independent manner while being able to resist various attacks. In this paper, we propose a user authentication system, VocalLock, which senses the whole vocal tract during speaking to identify different individuals in a passphrase-independent manner on smartphones leveraging acoustic signals. VocalLock first utilizes FMCW on acoustic signals to characterize both the static shape and dynamic movements of the vocal tract during speaking, and then constructs a passphrase-independent user authentication model based on the unique characteristics of vocal tract through GMM-UBM. The proposed VocalLock can resist various spoofing attacks, while achieving a satisfactory user experience. Extensive experiments in real environments demonstrate VocalLock can accurately authenticate user identity in a passphrase-independent manner and successfully resist various attacks.",class:"article{lu2020vocallock,<br>  title={Vocallock: Sensing vocal tract for passphrase-independent user authentication leveraging acoustic signals on smartphones},<br>  author={Lu, Li and Yu, Jiadi and Chen, Yingying and Wang, Yan},<br>  journal={Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},<br>  volume={4},<br>  number={2},<br>  pages={1--24},<br>  year={2020},<br>  publisher={ACM New York, NY, USA}<br>}"},{label:"Conference",year:"2020",topic:"Wearables",photo:"{{ site.baseurl }}/img/publications/infocom.png",pubname:"IEEE INFOCOM 2020",authors:"Tianming Zhao, Yan Wang, Jian Liu, Yingying Chen, Jerry Cheng, Jiadi Yu",src:"https://ieeexplore.ieee.org/abstract/document/9155526?casa_token=tJgFKFApuGgAAAAA:FdS2nzqj_NLdYfCxIqTgbEcCPdCx_7hpQ7IaLIJvwcDf92y2un_rBNGhrrU5iPIPdpal1D7eWQ",name:"TrueHeart: Continuous Authentication on Wrist-worn Wearables Using PPG-based Biometrics ",public:"Proceedings of IEEE International Conference on Computer Communications",acceptance:"(Acceptance rate: 268/1354=19.8%)",introduction:"Traditional one-time user authentication processes might cause friction and unfavorable user experience in many widely-used applications. This is a severe problem in particular for security-sensitive facilities if an adversary could obtain unauthorized privileges after a user’s initial login. Recently, continuous user authentication (CA) has shown its great potential by enabling seamless user authentication with few active participation. We devise a low-cost system exploiting a user’s pulsatile signals from the photoplethysmography (PPG) sensor in commercial wrist-worn wearables for CA. Compared to existing approaches, our system requires zero user effort and is applicable to practical scenarios with non-clinical PPG measurements having motion artifacts (MA). We explore the uniqueness of the human cardiac system and design an MA filtering method to mitigate the impacts of daily activities. Furthermore, we identify general fiducial features and develop an adaptive classifier using the gradient boosting tree (GBT) method. As a result, our system can authenticate users continuously based on their cardiac characteristics so little training effort is required. Experiments with our wrist-worn PPG sensing platform on 20 participants under practical scenarios demonstrate that our system can achieve a high CA accuracy of over 90% and a low false detection rate of 4% in detecting random attacks.",class:"inproceedings{zhao2020trueheart,<br>  title={Trueheart: Continuous authentication on wrist-worn wearables using ppg-based biometrics},<br>  author={Zhao, Tianming and Wang, Yan and Liu, Jian and Chen, Yingying and Cheng, Jerry and Yu, Jiadi},<br>  booktitle={IEEE INFOCOM 2020-IEEE Conference on Computer Communications},<br>  pages={30--39},<br>  year={2020},<br>  organization={IEEE}<br>}"},{label:"Conference",year:"2020",topic:"Others",photo:"{{ site.baseurl }}/img/publications/infocom.png",pubname:"IEEE INFOCOM 2020",authors:"Jian Liu, Yingying Chen, Yudi Dong, Yan Wang, Tianming Zhao, Yu-Donng Yao",src:"https://ieeexplore.ieee.org/abstract/document/9155258?casa_token=W_e25zZ7IvAAAAAA:chWAhTxMtUnG8BoZqjn6NDGbbOGL8I5x1ryHuSjEtdV38S__gpD9TXC2UkhBTIP0vZbpLrsqXA",name:"Continuous User Verification via Respiratory Biometrics",public:"Proceedings of IEEE International Conference on Computer Communications",acceptance:"(Acceptance rate: 268/1354=19.8%)",introduction:"The ever-growing security issues in various mobile applications and smart devices create an urgent demand for a reliable and convenient user verification method. Traditional verification methods request users to provide their secrets (e.g., entering passwords and collecting fingerprints). We envision that the essential trend of user verification is to free users from active participation in the verification process. Toward this end, we propose a continuous user verification system, which re-uses the widely deployed WiFi infrastructure to capture the unique physiological characteristics rooted in user's respiratory motions. Different from the existing continuous verification approaches, posing dependency on restricted scenarios/user behaviors (e.g., keystrokes and gaits), our system can be easily integrated into any WiFi infrastructure to provide non-intrusive continuous verification. Specifically, we extract the respiration-related signals from the channel state information (CSI) of WiFi. We then derive the user-specific respiratory features based on the waveform morphology analysis and fuzzy wavelet transformation of the respiration signals. Additionally, a deep learning based user verification scheme is developed to identify legitimate users accurately and detect the existence of spoofing attacks. Extensive experiments involving 20 participants demonstrate that the proposed system can robustly verify/identify users and detect spoofers under various types of attacks.",class:"INPROCEEDINGS{9155258,<br>  author={Liu, Jian and Chen, Yingying and Dong, Yudi and Wang, Yan and Zhao, Tiannming and Yao, Yu-Dong},<br>  booktitle={IEEE INFOCOM 2020 - IEEE Conference on Computer Communications}, <br>  title={Continuous User Verification via Respiratory Biometrics}, <br>  year={2020},<br>  volume={},<br>  number={},<br>  pages={1-10},<br>  doi={10.1109/INFOCOM41043.2020.9155258}}"},{label:"Conference",year:"2020",topic:"Others",photo:"{{ site.baseurl }}/img/publications/infocom.png",pubname:"IEEE INFOCOM 2020",authors:"Hongbo Liu, Zhihua Li, Yucheng Xie, Ruizhe Jiang, Yan Wang, Xiaonan Guo, Yingying Chen",src:"https://ieeexplore.ieee.org/abstract/document/9155400?casa_token=cFM_JPhBIWwAAAAA:rfXqYtKJoAZFL7caQ84kEUmqFsqgCH9EjhhEzL_0nVcqXjyv_kzOoimx8cD1dJDuyy9aKWMkcQ",name:"LiveScreen: Video Chat Liveness Detection Leveraging Skin Reflection",public:"Proceedings of IEEE International Conference on Computer Communications",acceptance:"(Acceptance rate: 268/1354=19.8%)",introduction:"The rapid advancement of social media and communication technology enables video chat to become an important and convenient way of daily communication. However, such convenience also makes personal video clips easily obtained and exploited by malicious users who launch scam attacks. Existing studies only deal with the attacks that use fabricated facial masks, while the liveness detection that targets the playback attacks using a virtual camera is still elusive. In this work, we develop a novel video chat liveness detection system, LiveScreen, which can track the weak light changes reflected off the skin of a human face leveraging chromatic eigenspace differences. We design an inconspicuous challenge frame with minimal intervention to the video chat and develop a robust anomaly frame detector to verify the liveness of the remote user in the video chat using the response to the challenge frame. Furthermore, we propose resilient defense strategies to defeat both naive and intelligent playback attacks leveraging spatial and temporal verification. We implemented a prototype over both laptop and smartphone platforms and conducted extensive experiments in various realistic scenarios. We show that our system can achieve robust liveness detection with accuracy and false detection rates 97.7% (94.8%) and 1% (1.6%) on smartphones (laptops), respectively.",class:"inproceedings{liu2020livescreen,<br>  title={LiveScreen: Video chat liveness detection leveraging skin reflection},<br>  author={Liu, Hongbo and Li, Zhihua and Xie, Yucheng and Jiang, Ruizhe and Wang, Yan and Guo, Xiaonan and Chen, Yingying},<br>  booktitle={IEEE INFOCOM 2020-IEEE Conference on Computer Communications},<br>  pages={1083--1092},<br>  year={2020},<br>  organization={IEEE}<br>}"},{label:"Conference",year:"2019",topic:"Acoustic",photo:"{{ site.baseurl }}/img/publications/infocom.png",pubname:"IEEE INFOCOM 2019",authors:"Chen Wang, Jian Liu, Xiaonan Guo, Yan Wang, Yingying Chen",src:"https://ieeexplore.ieee.org/abstract/document/8737591?casa_token=xwkRWw6l3lEAAAAA:Z3Nfq8c1bJhVys0biQRHGisklZkZ2Nqc6SM8La8MAy2J2N296lRvqQZ-nQYXk9QCyR9ZOosxug",name:"WristSpy: Snooping Passcodes in Mobile Payment Using Wrist-worn Wearables",public:"Proceedings of IEEE International Conference on Computer Communications",acceptance:"(Acceptance rate: 288/1464 = 19.7%)",introduction:"This paper demonstrates the feasibility of a side-channel attack to infer keystrokes on touch screen leveraging an off-the-shelf smartphone. Although there exist some studies on keystroke eavesdropping attacks on touch screen, they are mainly direct eavesdropping attacks, i.e., require the device of victims compromised to provide side-channel information for the adversary, which are hardly launched in practical scenarios. In this work, we show the practicability of an indirect eavesdropping attack, KeyListener, which infers keystrokes on QWERTY keyboards of touch screen leveraging audio devices on a smartphone. We investigate the attenuation of acoustic signals, and find that a user's keystroke fingers can be localized through the attenuation of acoustic signals received by the microphones in the smartphone. We then utilize the attenuation of acoustic signals to localize each keystroke, and further analyze errors induced by ambient noises. To improve the accuracy of keystroke localization, KeyListener further tracks finger movements during inputs through phase change and Doppler effect to reduce errors of acoustic signal attenuation-based keystroke localization. In addition, a binary tree-based search approach is employed to infer keystrokes in a context-aware manner. The proposed keystroke eavesdropping attack is robust to various environments without the assistance of additional infrastructures. Extensive experiments demonstrate that the accuracy of keystroke inference in top-5 candidates can approach 90% with a top-5 error rate of around 6%, which is a strong indication of the possible user privacy leakage of inputs on QWERTY keyboard.",class:"inproceedings{lu2019keylistener,<br>  title={Keylistener: Inferring keystrokes on qwerty keyboard of touch screen through acoustic signals},<br>  author={Lu, Li and Yu, Jiadi and Chen, Yingying and Zhu, Yanmin and Xu, Xiangyu and Xue, Guangtao and Li, Minglu},<br>  booktitle={IEEE INFOCOM 2019-IEEE Conference on Computer Communications},<br>  pages={775--783},<br>  year={2019},<br>  organization={IEEE}<br>}"},{label:"Conference",year:"before",topic:"WiFi",photo:"{{ site.baseurl }}/img/publications/infocom.png",pubname:"IEEE CNS 2018",authors:"Chen Wang, Jian Liu, Yingying Chen, Hongbo Liu, Yan Wang",src:"https://ieeexplore.ieee.org/abstract/document/8433142?casa_token=6122yprl0OkAAAAA:4I6W2mz4BNmg-ZoHV52Trg_x8x-f7Qua2UzRe10y5IUj4rjCMg1lZhWfVyvb5AZ3_IZCplSHkg",name:"Towards In-baggage Suspicious Object Detection Using Commodity WiFi",public:"Proceedings of IEEE International Communications and Network Security ",acceptance:"Best Paper Award",introduction:"The growing needs of public safety urgently require scalable and low-cost techniques on detecting dangerous objects (e.g., lethal weapons, homemade-bombs, explosive chemicals) hidden in baggage. Traditional baggage check involves either high manpower for manual examinations or expensive and specialized instruments, such as X-ray and CT. As such, many public places (i.e., museums and schools) that lack of strict security check are exposed to high risk. In this work, we propose to utilize the fine-grained channel state information (CSI) from off-the-shelf WiFi to detect suspicious objects that are suspected to be dangerous (i.e., defined as any metal and liquid object) without penetrating into the user's privacy through physically opening the baggage. Our suspicious object detection system significantly reduces the deployment cost and is easy to set up in public venues. Towards this end, our system is realized by two major components: it first detects the existence of suspicious objects and identifies the dangerous material type based on the reconstructed CSI complex value (including both amplitude and phase information); it then determines the risk level of the object by examining the object's dimension (i.e., liquid volume and metal object's shape) based on the reconstructed CSI complex of the signals reflected by the object. Extensive experiments are conducted with 15 metal and liquid objects and 6 types of bags in a 6-month period. The results show that our system can detect over 95% suspicious objects in different types of bags and successfully identify 90% dangerous material types. In addition, our system can achieve the average errors of 16ml and 0.5cm when estimating the volume of liquid and shape (i.e., width and height) of metal objects, respectively.",class:"inproceedings{wang2018towards,<br>  title={Towards in-baggage suspicious object detection using commodity wifi},<br>  author={Wang, Chen and Liu, Jian and Chen, Yingying and Liu, Hongbo and Wang, Yan},<br>  booktitle={2018 IEEE Conference on Communications and Network Security (CNS)},<br>  pages={1--9},<br>  year={2018},<br>  organization={IEEE}<br>}"},{label:"Conference",year:"before",topic:"Wearables",photo:"{{ site.baseurl }}/img/publications/infocom.png",pubname:"IEEE INFOCOM 2018",authors:"Tianming Zhao, Jian Liu, Yan Wang, Hongbo Liu, Yingying Chen",src:"https://ieeexplore.ieee.org/abstract/document/8486006?casa_token=ZUJrasdHpb8AAAAA:0_AbJyc05165nGfyBFEVSIKzuWCIl9Wx9EA3u5zLqzwU35v8rtPz53Ukwu0yXch5IUD_WqGSJg",name:"PPG-based Finger-level Gesture Recognition Leveraging Wearables",public:"Proceedings of IEEE International Conference on Computer Communications",acceptance:"(Acceptance rate: 309/1606 = 19.2%)",introduction:"This paper subverts the traditional understanding of Photoplethysmography (PPG) and opens up a new direction of the utility of PPG in commodity wearable devices, especially in the domain of human computer interaction of fine-grained gesture recognition. We demonstrate that it is possible to leverage the widely deployed PPG sensors in wrist-worn wearable devices to enable finger-level gesture recognition, which could facilitate many emerging human-computer interactions (e.g., sign-language interpretation and virtual reality). While prior solutions in gesture recognition require dedicated devices (e.g., video cameras or IR sensors) or leverage various signals in the environments (e.g., sound, RF or ambient light), this paper introduces the first PPG-based gesture recognition system that can differentiate fine-grained hand gestures at finger level using commodity wearables. Our innovative system harnesses the unique blood flow changes in a user's wrist area to distinguish the user's finger and hand movements. The insight is that hand gestures involve a series of muscle and tendon movements that compress the arterial geometry with different degrees, resulting in significant motion artifacts to the blood flow with different intensity and time duration. By leveraging the unique characteristics of the motion artifacts to PPG, our system can accurately extract the gesture-related signals from the significant background noise (i.e., pulses), and identify different minute finger-level gestures. Extensive experiments are conducted with over 3600 gestures collected from 10 adults. Our prototype study using two commodity PPG sensors can differentiate nine finger-level gestures from American Sign Language with an average recognition accuracy over 88%, suggesting that our PPG-based finger-level gesture recognition system is promising to be one of the most critical components in sign language translation using wearables.",class:"inproceedings{zhao2018ppg,<br>  title={PPG-based finger-level gesture recognition leveraging wearables},<br>  author={Zhao, Tianming and Liu, Jian and Wang, Yan and Liu, Hongbo and Chen, Yingying},<br>  booktitle={IEEE INFOCOM 2018-IEEE Conference on Computer Communications},<br>  pages={1457--1465},<br>  year={2018},<br>  organization={IEEE}<br>}"},{label:"Conference",year:"before",topic:"Others",photo:"{{ site.baseurl }}/img/publications/mobisys.png",pubname:"ACM MobiSys 2017",authors:"Luyang Liu, Hongyu Li, Jian Liu, Cagdas Karatas, Yan Wang, Marco Gruteser, Yingying Chen, Richard Martin",src:"https://dl.acm.org/doi/abs/10.1145/3081333.3081344",name:"BigRoad: Scaling Massive Road Data Acquisition for Dependable Self-Driving",public:"Proceedings of the 15th ACM International Conference on Mobile Systems, Applications, and Services",acceptance:"(Acceptance rate: 34/191 = 17.8%)",introduction:"Advanced driver assistance systems and, in particular automated driving offers an unprecedented opportunity to transform the safety, efficiency, and comfort of road travel. Developing such safety technologies requires an understanding of not just common highway and city traffic situations but also a plethora of widely different unusual events (e.g., object on the road way and pedestrian crossing highway, etc.). While each such event may be rare, in aggregate they represent a significant risk that technology must address to develop truly dependable automated driving and traffic safety technologies. By developing technology to scale road data acquisition to a large number of vehicles, this paper introduces a low-cost yet reliable solution, BigRoad, that can derive internal driver inputs (i.e., steering wheel angles, driving speed and acceleration) and external perceptions of road environments (i.e., road conditions and front-view video) using a smartphone and an IMU mounted in a vehicle. We evaluate the accuracy of collected internal and external data using over 140 real-driving trips collected in a 3-month time period. Results show that BigRoad can accurately estimate the steering wheel angle with 0.69 degree median error, and derive the vehicle speed with 0.65 km/h deviation. The system is also able to determine binary road conditions with 95% accuracy by capturing a small number of brakes. We further validate the usability of BigRoad by pushing the collected video feed and steering wheel angle to a deep neural network steering wheel angle predictor, showing the potential of massive data acquisition for training self-driving system using BigRoad.",class:"inproceedings{liu2017bigroad,<br>  title={Bigroad: Scaling road data acquisition for dependable self-driving},<br>  author={Liu, Luyang and Li, Hongyu and Liu, Jian and Karatas, Cagdas and Wang, Yan and Gruteser, Marco and Chen, Yingying and Martin, Richard P},<br>  booktitle={Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},<br>  pages={371--384},<br>  year={2017}<br>}"},{label:"Conference",year:"before",topic:"Others",photo:"{{ site.baseurl }}/img/publications/secon.png",pubname:"IEEE SECON 2017",authors:"Jian Liu, Yingying Chen, Marco Gruteser, Yan Wang",src:"https://ieeexplore.ieee.org/abstract/document/7964907?casa_token=mnrGZt0yMRQAAAAA:0AEDYYxK1tB96kv87gpSUEAy3BDmxmMtQVcOi493OyMQJOK3PVtcPfqmRyxLOzfGMP4mhGb-cw",name:"VibSense: Sensing Touches on Ubiquitous Surfaces through Vibration",public:"Proceedings of the 14th IEEE International Conference on Sensing, Communication and Networking",acceptance:"(Acceptance rate: 45/170 = 26.5%)",introduction:"VibSense pushes the limits of vibration-based sensing to determine the location of a touch on extended surface areas as well as identify the object touching the surface leveraging a single sensor. Unlike capacitive sensing, it does not require conductive materials and compared to audio sensing it is more robust to acoustic noise. It supports a broad array of applications through either passive or active sensing using only a single sensor. In VibSense's passive sensing, the received vibration signals are determined by the location of the touch impact. This allows location discrimination of touches precise enough to enable emerging applications such as virtual keyboards on ubiquitous surfaces for mobile devices. Moreover, in the active mode, the received vibration signals carry richer information of the touching object's characteristics (e.g., weight, size, location and material). This further enables VibSense to match the signals to the trained profiles and allows it to differentiate personal objects in contact with any surface. VibSense is evaluated extensively in the use cases of localizing touches (i.e., virtual keyboards), object localization and identification. Our experimental results demonstrate that VibSense can achieve high accuracy, over 95%, in all these use cases.",class:"inproceedings{liu2017vibsense,<br>  title={Vibsense: Sensing touches on ubiquitous surfaces through vibration},<br>  author={Liu, Jian and Chen, Yingying and Gruteser, Marco and Wang, Yan},<br>  booktitle={2017 14th Annual IEEE International Conference on Sensing, Communication, and Networking (SECON)},<br>  pages={1--9},<br>  year={2017},<br>  organization={IEEE}<br>}"},{label:"Conference",year:"before",topic:"Wearables",photo:"{{ site.baseurl }}/img/publications/asiaccs.png",pubname:"IEEE ASIACCS 2016",authors:"Chen Wang, Xiaonan Guo, Yan Wang, Yingying Chen, Bo Liu",src:"https://dl.acm.org/doi/abs/10.1145/2897845.2897847",name:"Friend or Foe? Your Wearable Devices Reveal Your Personal PIN",public:"Proceedings of the 11th ACM Asia Conference on Computer and Communications Security",acceptance:"(Acceptance rate: 20.9%) Best Paper Award",introduction:"The proliferation of wearable devices, e.g., smartwatches and activity trackers, with embedded sensors has already shown its great potential on monitoring and inferring human daily activities. This paper reveals a serious security breach of wearable devices in the context of divulging secret information (i.e., key entries) while people accessing key-based security systems. Existing methods of obtaining such secret information relies on installations of dedicated hardware (e.g., video camera or fake keypad), or training with labeled data from body sensors, which restrict use cases in practical adversary scenarios. In this work, we show that a wearable device can be exploited to discriminate mm-level distances and directions of the user's fine-grained hand movements, which enable attackers to reproduce the trajectories of the user's hand and further to recover the secret key entries. In particular, our system confirms the possibility of using embedded sensors in wearable devices, i.e., accelerometers, gyroscopes, and magnetometers, to derive the moving distance of the user's hand between consecutive key entries regardless of the pose of the hand. Our Backward PIN-Sequence Inference algorithm exploits the inherent physical constraints between key entries to infer the complete user key entry sequence. Extensive experiments are conducted with over 5000 key entry traces collected from 20 adults for key-based security systems (i.e. ATM keypads and regular keyboards) through testing on different kinds of wearables. Results demonstrate that such a technique can achieve 80% accuracy with only one try and more than 90% accuracy with three tries, which to our knowledge, is the first technique that reveals personal PINs leveraging wearable devices without the need for labeled training data and contextual information.",class:"inproceedings{wang2016friend,<br>  title={Friend or foe? Your wearable devices reveal your personal pin},<br>  author={Wang, Chen and Guo, Xiaonan and Wang, Yan and Chen, Yingying and Liu, Bo},<br>  booktitle={Proceedings of the 11th ACM on Asia Conference on Computer and Communications Security},<br>  pages={189--200},<br>  year={2016}<br>}"},{label:"Conference",year:"before",topic:"Wearables",photo:"{{ site.baseurl }}/img/publications/infocom.png",pubname:"IEEE INFOCOM 2016",authors:"Cagdas Karatas, Luyang Liu, Hongyu Li, Jian Liu, Yan Wang, Sheng Tan, Jie Yang, Yingying Chen, Marco Gruteser, Richard Martin",src:"https://ieeexplore.ieee.org/abstract/document/7524544?casa_token=HUnq8hikomYAAAAA:U2XKvPoj7o8SuACiJOdfFCnP6b2GKReX7P82n8hk_rxNKlaDmnOlPfJst0F9ziVT4hEKqnTJaA",name:"Leveraging Wearables for Steering and Driver Tracking",public:"Proceedings of IEEE International Conference on Computer Communications",acceptance:"(Acceptance rate: 300/1644 = 18.25%)",introduction:"Given the increasing popularity of wearable devices, this paper explores the potential to use wearables for steering and driver tracking. Such capability would enable novel classes of mobile safety applications without relying on information or sensors in the vehicle. In particular, we study how wrist-mounted inertial sensors, such as those in smart watches and fitness trackers, can track steering wheel usage and angle. In particular, tracking steering wheel usage and turning angle provide fundamental techniques to improve driving detection, enhance vehicle motion tracking by mobile devices and help identify unsafe driving. The approach relies on motion features that allow distinguishing steering from other confounding hand movements. Once steering wheel usage is detected, it further uses wrist rotation measurements to infer steering wheel turning angles. Our on-road experiments show that the technique is 99% accurate in detecting steering wheel usage and can estimate turning angles with an average error within 3.4 degrees.",class:"inproceedings{karatas2016leveraging,<br>  title={Leveraging wearables for steering and driver tracking},<br>  author={Karatas, Cagdas and Liu, Luyang and Li, Hongyu and Liu, Jian and Wang, Yan and Tan, Sheng and Yang, Jie and Chen, Yingying and Gruteser, Marco and Martin, Richard},<br>  booktitle={IEEE INFOCOM 2016-The 35th Annual IEEE International Conference on Computer Communications},<br>  pages={1--9},<br>  year={2016},<br>  organization={IEEE}<br>}"},{label:"Conference",year:"before",topic:"Acoustic",photo:"{{ site.baseurl }}/img/publications/mobicom2015.png",pubname:"ACM Mobicom 2015",authors:"Jian Liu, Yan Wang, Gorkem Kar, Yingying Chen, Jie Yang, Marco Gruteser",src:"https://dl.acm.org/doi/abs/10.1145/2789168.2790122?casa_token=7hMlsB0AuusAAAAA:Du57fmxVJrrCCQKr_EPlHfkA0RD3K5k78JYa7eNqJkoGZ3bQ7d0sMfPk2iMjmBpNcutDBTMVxHr3",name:"Snooping Keystrokes with mmlevel Audio Ranging on a Single Phone",public:"Proceedings of the 21st Annual International Conference on Mobile Computing and Networking",acceptance:"(Acceptance rate: 38/207 = 18.4%)",introduction:"This paper explores the limits of audio ranging on mobile devices in the context of a keystroke snooping scenario. Acoustic keystroke snooping is challenging because it requires distinguishing and labeling sounds generated by tens of keys in very close proximity. Existing work on acoustic keystroke recognition relies on training with labeled data, linguistic context, or multiple phones placed around a keyboard --- requirements that limit usefulness in an adversarial context. In this work, we show that mobile audio hardware advances can be exploited to discriminate mm-level position differences and that this makes it feasible to locate the origin of keystrokes from only a single phone behind the keyboard. The technique clusters keystrokes using time-difference of arrival measurements as well as acoustic features to identify multiple strokes of the same key. It then computes the origin of these sounds precise enough to identify and label each key. By locating keystrokes this technique avoids the need for labeled training data or linguistic context. Experiments with three types of keyboards and off-the-shelf smartphones demonstrate scenarios where our system can recover $94\%$ of keystrokes, which to our knowledge, is the first single-device technique that enables acoustic snooping of passwords.",class:"inproceedings{liu2015snooping,<br>  title={Snooping keystrokes with mm-level audio ranging on a single phone},<br>  author={Liu, Jian and Wang, Yan and Kar, Gorkem and Chen, Yingying and Yang, Jie and Gruteser, Marco},<br>  booktitle={Proceedings of the 21st Annual International Conference on Mobile Computing and Networking},<br>  pages={142--154},<br>  year={2015}<br>}"},{label:"Conference",year:"before",topic:"WiFi",photo:"{{ site.baseurl }}/img/publications/mobihoc2015.png",pubname:"ACM MobiHoc 2015",authors:"Jian Liu, Yan Wang, Yingying Chen, Jie Yang, Xu Chen, Jerry Cheng",src:"https://dl.acm.org/doi/abs/10.1145/2746285.2746303?casa_token=rJEGJF-feA4AAAAA:coAMBixUG6e8HDF5FUQaX80hmTyUbUhnuvxHQe0ehGlB1gIwDn6zouImgguQT5V_nehJL6BHO0Kp",name:"Tracking Vital Signs During Sleep Leveraging Off-the-shelf WiFi",public:"Proceedings of the 16th ACM Symposium on Mobile Ad Hoc Networking and Computing",acceptance:"(Acceptance rate: 14.8%)",introduction:"Tracking human vital signs of breathing and heart rates during sleep is important as it can help to assess the general physical health of a person and provide useful clues for diagnosing possible diseases. Traditional approaches (e.g., Polysomnography (PSG)) are limited to clinic usage. Recent radio frequency (RF) based approaches require specialized devices or dedicated wireless sensors and are only able to track breathing rate. In this work, we propose to track the vital signs of both breathing rate and heart rate during sleep by using off-the-shelf WiFi without any wearable or dedicated devices. Our system re-uses existing WiFi network and exploits the fine-grained channel information to capture the minute movements caused by breathing and heart beats. Our system thus has the potential to be widely deployed and perform continuous long-term monitoring. The developed algorithm makes use of the channel information in both time and frequency domain to estimate breathing and heart rates, and it works well when either individual or two persons are in bed. Our extensive experiments demonstrate that our system can accurately capture vital signs during sleep under realistic settings, and achieve comparable or even better performance comparing to traditional and existing approaches, which is a strong indication of providing non-invasive, continuous fine-grained vital signs monitoring without any additional cost.",class:"inproceedings{liu2015tracking,<br>  title={Tracking vital signs during sleep leveraging off-the-shelf wifi},<br>  author={Liu, Jian and Wang, Yan and Chen, Yingying and Yang, Jie and Chen, Xu and Cheng, Jerry},<br>  booktitle={Proceedings of the 16th ACM international symposium on mobile ad hoc networking and computing},<br>  pages={267--276},<br>  year={2015}<br>}"},{label:"Conference",year:"before",topic:"Others",photo:"{{ site.baseurl }}/img/publications/default.png",pubname:"IEEE ICDCS 2015",authors:"Yan Wang, Yingying Chen, Fan Ye, Jie Yang, Hongbo Liu",src:"https://ieeexplore.ieee.org/abstract/document/7164915?casa_token=LA6yX_aS_egAAAAA:vt_nEF4wkwhASzQ3ToQCV9ZhQWNnisSMO8diwNex9v2Seo_aU6fxLrZ4VPgAhRrtui3YJBRH1Q",name:"Towards Understanding the Advertiser's Perspective of Smartphone User Privacy",public:"Proceedings of the 35th IEEE International Conference on Distributed Computing System",acceptance:"(Acceptance rate: 70/543 = 12.8%)",introduction:"Many smartphone apps routinely gather various private user data and send them to advertisers. Despite recent study on protection mechanisms and analysis on apps' behavior, the understanding about the consequences of such privacy losses remains limited. In this paper we investigate how much an advertiser can infer about users' social and community relationships by combining data from multiple applications and across many users. After one month's user study involving about 200 most popular Android apps, we find that an advertiser can infer 90% of the social relationships. We further propose a privacy leakage inference framework and use real mobility traces and Foursquare data to quantify the consequences of privacy leakage. We find that achieving 90% inference accuracy of the social and community relationships requires merely 3 weeks' user data. The discoveries underscore the importance of early adoption of privacy protection mechanisms.",class:"inproceedings{wang2015towards,<br>  title={Towards understanding the advertiser's perspective of smartphone user privacy},<br>  author={Wang, Yan and Chen, Yingying and Ye, Fan and Yang, Jie and Liu, Hongbo},<br>  booktitle={2015 IEEE 35th International Conference on Distributed Computing Systems},<br>  pages={288--297},<br>  year={2015},<br>  organization={IEEE}<br>}"},{label:"Conference",year:"before",topic:"Others",photo:"{{ site.baseurl }}/img/publications/ccs2014.png",pubname:"ACM CCS 2014",authors:"Gorkem Kar, Hossen Mustafa, Yan Wang, Yingying Chen, Wenyuan Xu, Marco Gruteser, Tam Vu",src:"https://dl.acm.org/doi/abs/10.1145/2660267.2660336?casa_token=Bjx7jB8NiDoAAAAA:aR4WSe0rsVj2-hdAu1vXOzyhaMOzE2S8rK2-I9jhjxV9Vha3oO4vvRgcDMPCW1yN-2OWnzI_jDNf",name:"Detection of On-Road Vehicles Emanating GPS Interference",public:"Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security",acceptance:"(Acceptance rate: 114/585 = 19.5%)",introduction:"The Global Positioning System (GPS) is widely used in critical infrastructures but is vulnerable to radio frequency (RF) interference. A common source of interference are commercial drivers that use GPS jammers to circumvent vehicle tracking systems. Existing mechanisms to detect and identify such interference emitting vehicles on roadways require a large number of specialized detectors or a manual observation process. In this paper, we design a practical, automated system to facilitate enforcement actions. Our system combines information from roadside monitoring points at key locations along the roadway as well as mobile detectors (e.g., smartphones and other mobile GPS systems). Rather than attempting precise localization at a given time, the system exploits the inherent variation in driving speeds and the resulting diverging trajectories of vehicles to uniquely identify the interfering vehicle. Through our experiments on a local highway with a vehicle transmitting interference in the 900MHz ISM band, we found that the vehicle identification rate of our mechanism is 65% for a single-point setup and 100% for a two-point setup. We performed 200 hours of passive monitoring of GPS L1 band on roadways and found two episodes of real interference. We also demonstrate that our mobile detector-based crowdsourced smartphone profiles are sufficiently consistent in time and space to enable reliable interference detection.",class:"inproceedings{kar2014detection,<br>  title={Detection of on-road vehicles emanating GPS interference},<br>  author={Kar, Gorkem and Mustafa, Hossen and Wang, Yan and Chen, Yingying and Xu, Wenyuan and Gruteser, Marco and Vu, Tam},<br>  booktitle={Proceedings of the 2014 ACM SIGSAC conference on computer and communications security},<br>  pages={621--632},<br>  year={2014}<br>}"},{label:"Conference",year:"before",topic:"WiFi",photo:"{{ site.baseurl }}/img/publications/mobicom2014.png",pubname:"ACM Mobicom 2014",authors:"Yan Wang, Jian Liu, Yingying Chen, Marco Gruteser, Jie Yang, Hongbo Liu",src:"https://dl.acm.org/doi/abs/10.1145/2639108.2639143?casa_token=Mxjiy5Ve3IwAAAAA:xl2c_6qGmPQiMALxEHmUUIiJnypAhJJ06sQ4Onm574nZZxgZbX5jjZQFsVi_1BESzxf5Q6Kvx0qN",name:"E-eyes: Device-free Location-oriented Activity Identification Using Fine-grained WiFi Signatures",public:"Proceedings of the 20th Annual International Conference on Mobile Computing and Networking",acceptance:"(Acceptance rate: 36/220 = 16.4%)",introduction:"Activity monitoring in home environments has become increasingly important and has the potential to support a broad array of applications including elder care, well-being management, and latchkey child safety. Traditional approaches involve wearable sensors and specialized hardware installations. This paper presents device-free location-oriented activity identification at home through the use of existing WiFi access points and WiFi devices (e.g., desktops, thermostats, refrigerators, smartTVs, laptops). Our low-cost system takes advantage of the ever more complex web of WiFi links between such devices and the increasingly fine-grained channel state information that can be extracted from such links. It examines channel features and can uniquely identify both in-place activities and walking movements across a home by comparing them against signal profiles. Signal profiles construction can be semi-supervised and the profiles can be adaptively updated to accommodate the movement of the mobile devices and day-to-day signal calibration. Our experimental evaluation in two apartments of different size demonstrates that our approach can achieve over 96% average true positive rate and less than 1% average false positive rate to distinguish a set of in-place and walking activities with only a single WiFi access point. Our prototype also shows that our system can work with wider signal band (802.11ac) with even higher accuracy.",class:"inproceedings{wang2014eyes,<br>  title={E-eyes: device-free location-oriented activity identification using fine-grained wifi signatures},<br>  author={Wang, Yan and Liu, Jian and Chen, Yingying and Gruteser, Marco and Yang, Jie and Liu, Hongbo},<br>  booktitle={Proceedings of the 20th annual international conference on Mobile computing and networking},<br>  pages={617--628},<br>  year={2014}<br>}"},{label:"Conference",year:"before",topic:"Others",photo:"{{ site.baseurl }}/img/publications/mobisys2014.png",pubname:"ACM MobiSys 2014",authors:"Yan Wang, Jie Yang, Yingying Chen, Hongbo Liu, Marco Gruteser, Richard P. Martin",src:"https://dl.acm.org/doi/abs/10.1145/2594368.2594382?casa_token=Q1O7jlyHKf0AAAAA:Pc_iSES-tIQg9McYyX83vfr9YeumdLwc9eVcLcJGSCnXHE_FXVuVCcz8m_yyZg898JBvrFCX3Rhe",name:"Tracking Human Queues Using Single-Point Signal Monitoring",public:"Proceedings of the 12th International Conference on Mobile Systems, Applications, and Services",acceptance:"(Acceptance rate: 25/185 = 13.5%)",introduction:"We investigate using smartphone WiFi signals to track human queues, which are common in many business areas such as retail stores, airports, and theme parks. Real-time monitoring of such queues would enable a wealth of new applications, such as bottleneck analysis, shift assignments, and dynamic workflow scheduling. We take a minimum infrastructure approach and thus utilize a single monitor placed close to the service area along with transmitting phones. Our strategy extracts unique features embedded in signal traces to infer the critical time points when a person reaches the head of the queue and finishes service, and from these inferences we derive a person's waiting and service times. We develop two approaches in our system, one is directly feature-driven and the second uses a simple Bayesian network. Extensive experiments conducted both in the laboratory as well as in two public facilities demonstrate that our system is robust to real-world environments. We show that in spite of noisy signal readings, our methods can measure service and waiting times to within a $10$ second resolution.",class:"inproceedings{wang2014tracking,<br>  title={Tracking human queues using single-point signal monitoring},<br>  author={Wang, Yan and Yang, Jie and Chen, Yingying and Liu, Hongbo and Gruteser, Marco and Martin, Richard P},<br>  booktitle={Proceedings of the 12th annual international conference on Mobile systems, applications, and services},<br>  pages={42--54},<br>  year={2014}<br>}"},{label:"Conference",year:"before",topic:"Others",photo:"{{ site.baseurl }}/img/publications/asiaccs2014.png",pubname:"ACM ASIACCS 2014",authors:"Hongbo Liu, Yan Wang, Jian Liu, Jie Yang, Yingying Chen",src:"https://dl.acm.org/doi/abs/10.1145/2590296.2590321?casa_token=H0ceShW1uZwAAAAA:iPFOShzFUwo0VYDhcTu6QF_fjBpJDgK5h0r8gqcOsT5jZ02oc4zRm3QpoY2zUeWnJcAxvzqJfh-r",name:"Practical User Authentication Leveraging Channel State Information",public:"Proceedings of the 9th ACM Symposium on Information, Computer and Communications Security",acceptance:"(Acceptance rate: 52/260 = 20%)",introduction:"User authentication is the critical first step to detect identity-based attacks and prevent subsequent malicious attacks. However, the increasingly dynamic mobile environments make it harder to always apply the cryptographic-based methods for user authentication due to their infrastructural and key management overhead. Exploiting non-cryptographic based techniques grounded on physical layer properties to perform user authentication appears promising. In this work, we explore to use channel state information (CSI), which is available from off-the-shelf WiFi devices, to conduct fine-grained user authentication. We propose an user-authentication framework that has the capability to build the user profile resilient to the presence of the spoofer. Our machine learning based user-authentication techniques can distinguish two users even when they possess similar signal fingerprints and detect the existence of the spoofer. Our experiments in both office building and apartment environments show that our framework can filter out the signal outliers and achieve higher authentication accuracy compared with existing approaches using received signal strength (RSS).",class:"inproceedings{liu2014practical,<br>  title={Practical user authentication leveraging channel state information (CSI)},<br>  author={Liu, Hongbo and Wang, Yan and Liu, Jian and Yang, Jie and Chen, Yingying},<br>  booktitle={Proceedings of the 9th ACM symposium on Information, computer and communications security},<br>  pages={389--400},<br>  year={2014}<br>}"},{label:"Conference",year:"before",topic:"Others",photo:"{{ site.baseurl }}/img/publications/mobisys2013.png",pubname:"ACM MobiSys 2013",authors:"Yan Wang, Jie Yang, Hongbo Liu, Yingying Chen, Marco Gruteser, Richard P. Martin",src:"https://dl.acm.org/doi/abs/10.1145/2462456.2464447?casa_token=Y2Wxh9IdvKQAAAAA:SzbBiWlP13rg5isQ6txMk4Nfd8_n0Q77BOt-sylrCe99D0NkzL8aHJpurqhh_RW7vcYVXOj5KpeT",name:"Sensing Vehicle Dynamics for Determining Driver Phone Use",public:"Proceedings of the 11th International Conference on Mobile Systems, Applications, and Services",acceptance:"(Acceptance rate: 33/210=15.7%)",introduction:"This paper utilizes smartphone sensing of vehicle dynamics to determine driver phone use, which can facilitate many traffic safety applications. Our system uses embedded sensors in smartphones, i.e., accelerometers and gyroscopes, to capture differences in centripetal acceleration due to vehicle dynamics. These differences combined with angular speed can determine whether the phone is on the left or right side of the vehicle. Our low infrastructure approach is flexible with different turn sizes and driving speeds. Extensive experiments conducted with two vehicles in two different cities demonstrate that our system is robust to real driving environments. Despite noisy sensor readings from smartphones, our approach can achieve a classification accuracy of over $90\%$ with a false positive rate of a few percent. We also find that by combining sensing results in a few turns, we can achieve better accuracy (e.g., $95\%$) with a lower false positive rate.",class:"inproceedings{wang2013sensing,<br>  title={Sensing vehicle dynamics for determining driver phone use},<br>  author={Wang, Yan and Yang, Jie and Liu, Hongbo and Chen, Yingying and Gruteser, Marco and Martin, Richard P},<br>  booktitle={Proceeding of the 11th annual international conference on Mobile systems, applications, and services},<br>  pages={41--54},<br>  year={2013}<br>}"},{label:"Conference",year:"before",topic:"Others",photo:"{{ site.baseurl }}/img/publications/infocom.png",pubname:"IEEE INFOCOM 2013",authors:"Hongbo Liu, Yan Wang, Jie Yang, Yingying Chen",src:"https://ieeexplore.ieee.org/abstract/document/6567117?casa_token=0lmBnvq2ZLAAAAAA:z02g0fLv32Z7_qxsX927IPSHWIyuMUx50pL3dTd2Xh6SjojslQopL3eaxP4as-eUbjVokMlG2Q",name:"Fast and Practical Secret Key Extraction by Exploiting Channel Response",public:"Proceedings of the IEEE International Conference on Computer Communications",acceptance:"(Acceptance rate: 17%)",introduction:"Securing wireless communication remains challenging in dynamic mobile environments due to the shared nature of wireless medium and lacking of fixed key management infrastructures. Generating secret keys using physical layer information thus has drawn much attention to complement traditional cryptographic-based methods. Although recent work has demonstrated that Received Signal Strength (RSS) based secret key extraction is practical, existing RSS-based key generation techniques are largely limited in the rate they generate secret bits and are mainly applicable to mobile wireless networks. In this paper, we show that exploiting the channel response from multiple Orthogonal Frequency-Division Multiplexing (OFDM) subcarriers can provide fine-grained channel information and achieve higher bit generation rate for both static and mobile cases in real-world scenarios. We further develop a Channel Gain Complement (CGC) assisted secret key extraction scheme to cope with channel non-reciprocity encountered in practice. Our extensive experiments using WiFi networks in both indoor as well as outdoor environments demonstrate that our approach can achieve significantly faster secret bit generation rate at 60 ~ 90bit/packet, and is resilient to malicious attacks identified to be harmful to RSS-based techniques including predictable channel attack and stalking attack.",class:"inproceedings{liu2013fast,<br>  title={Fast and practical secret key extraction by exploiting channel response},<br>  author={Liu, Hongbo and Wang, Yang and Yang, Jie and Chen, Yingying},<br>  booktitle={2013 Proceedings IEEE INFOCOM},<br>  pages={3048--3056},<br>  year={2013},<br>  organization={IEEE}<br>}"},{label:"Conference",year:"before",topic:"WiFi",photo:"{{ site.baseurl }}/img/publications/mobicom2012.png",pubname:"ACM MobiCom 2022",authors:"Hongbo Liu, Yu Gan, Jie Yang, Simon Sidhom, Yan Wang, Yingying Chen, Fan Ye",src:"https://dl.acm.org/doi/abs/10.1145/2348543.2348581?casa_token=HSo6BbZcYbQAAAAA:-Bxiz1mJQP3fHaO9vdAIBzwHkP0zdb0GmmD9qzb_mFFba9mwLJ8Fb5x4vR8aPSx_MwgmFEFH0Hd9",name:"Push the Limit of WiFi based Localization for Smartphones",public:"Proceedings of the 18th Annual International Conference on Mobile Computing and Networking",acceptance:"(Acceptance rate: 32/212 = 15%)",introduction:"Highly accurate indoor localization of smartphones is critical to enable novel location based features for users and businesses. In this paper, we first conduct an empirical investigation of the suitability of WiFi localization for this purpose. We find that although reasonable accuracy can be achieved, significant errors (e.g., $6\sim8m$) always exist. The root cause is the existence of distinct locations with similar signatures, which is a fundamental limit of pure WiFi-based methods. Inspired by high densities of smartphones in public spaces, we propose a peer assisted localization approach to eliminate such large errors. It obtains accurate acoustic ranging estimates among peer phones, then maps their locations jointly against WiFi signature map subjecting to ranging constraints. We devise techniques for fast acoustic ranging among multiple phones and build a prototype. Experiments show that it can reduce the maximum and 80-percentile errors to as small as $2m$ and $1m$, in time no longer than the original WiFi scanning, with negligible impact on battery lifetime.",class:"inproceedings{liu2012push,<br>  title={Push the limit of WiFi based localization for smartphones},<br>  author={Liu, Hongbo and Gan, Yu and Yang, Jie and Sidhom, Simon and Wang, Yan and Chen, Yingying and Ye, Fan},<br>  booktitle={Proceedings of the 18th annual international conference on Mobile computing and networking},<br>  pages={305--316},<br>  year={2012}<br>}"},{label:"Conference",year:"before",topic:"Mobile",photo:"{{ site.baseurl }}/img/publications/globecom2012.jpg",pubname:"IEEE Globecom 2012",authors:"Yan Wang, Mooi-Choo Chuah, Yingying Chen",src:"https://ieeexplore.ieee.org/abstract/document/6503959?casa_token=ypggfFdjJAUAAAAA:6GBUOeCJCQb-AORTzjpCCtkOJnd4iuXNwvPlzOc7Mi5Zermqpx3uwO_24wKprmkHfSjXqgfcvA",name:"Incentive Driven Information Sharing in Delay Tolerant Mobile Networks",public:"Proceedings of the IEEE Global Communications Conference 2012 Wireless Networking Symposium ",acceptance:"",introduction:"Mobile wireless devices (e.g., smartphones, PDAs, and notebooks) play important roles in our daily life, e.g., users often use such devices for bank transactions, keep in touch with friends. Users can also store such information and share with one another via opportunistic peer to peer links. However, peer to peer links are opportunistic links which are intermittent in nature and hence require the store-and-forward feature proposed in Delay Tolerant Networks to provide useful data sharing opportunities. Moreover, due to the limited resources, e.g., communication bandwidth and battery consumption, mobile devices can be selfish and may not be willing to forward data items to other devices that are interested in such items. Hence, effective data dissemination schemes need to be designed to encourage nodes to collaboratively share data. In this paper, we propose a Multi-Receiver Incentive-Based Dissemination (MuRIS) scheme that allows nodes to cooperatively deliver information of interest to one another via chosen delivery paths that utilize few transmissions. Our MuRIS scheme utilizes local historical path and tracks users' interests information maintained by each node. In addition, the charge and reward functions incorporated within our MuRIS scheme stimulate cooperation among nodes such that the nodes have no incentive to launch edge insertion attacks. Furthermore, our charge and reward functions are designed such that the chosen delivery paths mimic efficient multicast tree that results in fewest delivery hops. Extensive simulation studies using real human contact-based mobility traces show that our MuRIS scheme outperforms existing methods in terms of delivery ratio and transmission efficiency.",class:"inproceedings{wang2012incentive,<br>  title={Incentive driven information sharing in delay tolerant mobile networks},<br>  author={Wang, Yan and Chuah, Mooi-Choo and Chen, Yingying},<br>  booktitle={2012 IEEE Global Communications Conference (GLOBECOM)},<br>  pages={5279--5284},<br>  year={2012},<br>  organization={IEEE}<br>}"},{label:"Conference",year:"before",topic:"Mobile",photo:"{{ site.baseurl }}/img/publications/infocom.png",pubname:"IEEE INFOCOM 2012",authors:"Hongbo Liu, Jie Yang, Yan Wang, Yingying Chen",src:"https://ieeexplore.ieee.org/abstract/document/6195843?casa_token=MjcxGxTX7osAAAAA:P7AQlRduTh564Yt8JllggQM_cfvIZTCsdwRpFvjuyUf09h6jOzyxBfOhPVlM4VVd5nQkZqVsvA",name:"Collaborative Secret Key Extraction Leveraging Received Signal Strength in Mobile Wireless Networks",public:"Proceedings of the IEEE International Conference on Computer Communications",acceptance:"(Acceptance rate: 18%)",introduction:"Securing communication in mobile wireless networks is challenging because the traditional cryptographic-based methods are not always applicable in dynamic mobile wireless environments. Using physical layer information of radio channel to generate keys secretly among wireless devices has been proposed as an alternative in wireless mobile networks. And the Received Signal Strength (RSS) based secret key extraction gains much attention due to the RSS readings are readily available in wireless infrastructure. However, the problem of using RSS to generate keys among multiple devices to ensure secure group communication remains open. In this work, we propose a framework for collaborative key generation among a group of wireless devices leveraging RSS. The proposed framework consists of a secret key extraction scheme exploiting the trend exhibited in RSS resulted from shadow fading, which is robust to outsider adversary performing stalking attacks. To deal with mobile devices not within each other's communication range, we employ relay nodes to achieve reliable key extraction. To enable secure group communication, two protocols, namely star-based and chain-based, are developed in our framework by exploiting RSS from multiple devices to perform group key generation collaboratively. Our experiments in both outdoor and indoor environments confirm the feasibility of using RSS for group key generation among multiple wireless devices under various mobile scenarios. The results also demonstrate that our collaborative key extraction scheme can achieve a lower bit mismatch rate compared to existing works when maintaining the comparable bit generation rate.",class:"inproceedings{liu2012collaborative,<br>  title={Collaborative secret key extraction leveraging received signal strength in mobile wireless networks},<br>  author={Liu, Hongbo and Yang, Jie and Wang, Yan and Chen, Yingying},<br>  booktitle={2012 Proceedings IEEE Infocom},<br>  pages={927--935},<br>  year={2012},<br>  organization={IEEE}<br>}"},{label:"Poster",year:"2022",topic:"Others",photo:"{{ site.baseurl }}/img/publications/default.png",pubname:"ACM MobiSys 2022",authors:"Tianfang Zhang, Cong Shi, Tianming Zhao, Zhengkun Ye, Payton Walker, Nitesh Saxena, Yan Wang, Yingying Chen",src:"https://dl.acm.org/doi/abs/10.1145/3498361.3538768?casa_token=Q-E6DhdZFJ0AAAAA:vy2XFZfLqqqkxkpJUXrGUgcz-OBrl8NojBnYoOzl0gHUOOSdZOrJ_kIZRCvglnnI2dkgGaZBCv8W",name:"Poster: Personalized Health Monitoring via Vital Sign Measurements Leveraging Motion Sensors on AR/VR Headsets",public:"Proceedings of the 20th ACM International Conference on Mobile Systems, Applications, and Services (MobiSys 2022), Poster Session, Portland, Oregon, June 2022.",acceptance:"",introduction:"Augmented reality/virtual reality (AR/VR) headsets have attracted millions of users and gained predictable popularity. However, long-period usage of immersive technology may lead to health issues (e.g., cybersickness, anxiety). In this poster, we design a low-cost and personalized healthcare monitoring system grounded on vital sign tracking (i.e., breathing and heartbeat rate tracking), by exploiting built-in AR/VR motion sensors. The key insight is that the conductive vibrations induced by chest and heart movements can propagate through the user's cranial bones, thereby vibrating the AR/VR headset mounted on the user's head. To realize this system, we design signal processing techniques to cancel the human motions and derive the periods of breathing and heartbeat through frequency-domain analyses. We further design a user identification scheme based on respiratory and cardiac biometrics, which works with vital sign monitoring to provide personalized healthcare recommendations. Our experiment shows that the proposed scheme can achieve less than 5.7% error rate on breathing/heartbeat rate estimation and 95% accuracy on user identification.",class:"inproceedings{zhang2022personalized,<br>  title={Personalized health monitoring via vital sign measurements leveraging motion sensors on AR/VR headsets},<br>  author={Zhang, Tianfang and Shi, Cong and Zhao, Tianming and Ye, Zhengkun and Walker, Payton and Saxena, Nitesh and Wang, Yan and Chen, Yingying},<br>  booktitle={Proceedings of the 20th Annual International Conference on Mobile Systems, Applications and Services},<br>  pages={529--530},<br>  year={2022}<br>}"},{label:"Poster",year:"2022",topic:"Others",photo:"{{ site.baseurl }}/img/publications/default.png",pubname:"ACM MobiSys 2022",authors:"Tianming Zhao, Zhengkun Ye, Tianfang Zhang, Cong Shi, Ahmed Tanvir Mahdad, Yan Wang, Yingying Chen, Nitesh Saxena",src:"https://dl.acm.org/doi/abs/10.1145/3498361.3538798?casa_token=dHqdVifKHGAAAAAA:LeaLq7vdk-t8iM-KEG3NBDFWzDxNbH0GD41XYsRzL8i0Ikr6xcN13mdVMspdlZqT5yW5X0_t-Rys",name:"Poster: Continuous Blood Pressure Monitoring Using Low-cost Motion Sensors on AR/VR Headsets",public:"Proceedings of the 20th ACM International Conference on Mobile Systems, Applications, and Services (MobiSys 2022), Poster Session, Portland, Oregon, June 2022.",acceptance:"",introduction:"The Augmented reality/Virtual reality (AR/VR) industry has ushered in a period of rapid development. The next decade leaves a massive imagination for AR/VR in terms of end product form, software, content, applications, and user increment. The AR & VR technology offers a gazillion of possibilities for smart healthcare. In this poster, we develop an innovative continuous blood pressure (CBP) estimation system leveraging the built-in motion sensors of AR/VR headsets for users. We design a deep learning-based PPG construction scheme using the motion sensor-based cardiac signal and estimate the continuous blood pressure using the regression model. Our experimental results show that our system can continuously estimate both systolic blood pressure (SBP) and diastolic blood pressure (DBP) with a mean error of less than 4 mmHg and 0.9 mmHg respectively within a day.",class:"inproceedings{zhao2022continuous,<br>  title={Continuous blood pressure monitoring using low-cost motion sensors on AR/VR headsets},<br>  author={Zhao, Tianming and Ye, Zhengkun and Zhang, Tianfang and Shi, Cong and Mahdad, Ahmed Tanvir and Wang, Yan and Chen, Yingying and Saxena, Nitesh},<br>  booktitle={Proceedings of the 20th Annual International Conference on Mobile Systems, Applications and Services},<br>  pages={589--590},<br>  year={2022}<br>}"},{label:"Poster",year:"2019",topic:"Wearables",photo:"{{ site.baseurl }}/img/publications/mobicom2019.png",pubname:"ACM MobiCom 2019",authors:"Tianming Zhao, Yan Wang, Jian Liu, Yingying Chen",src:"https://dl.acm.org/doi/abs/10.1145/3300061.3343375",name:"Demo: Toward Continuous User Authentication Using PPG in Commodity Wrist-worn Wearables",public:"Proceedings of the 25th Annual International Conference on Mobile Computing and Networking (MobiCom 2019), Demo Session, Los Cabos, Mexico, October 2019.",acceptance:"",introduction:"We present a photoplethysmography (PPG)-based continuous user authentication (CA) system leveraging the pervasively equipped PPG sensor in commodity wrist-worn wearables such as the smartwatch. Compared to existing approaches, our system does not require any users' interactions (e.g., performing specific gestures) and is applicable to practical scenarios where the user's daily activities cause motion artifacts (MA). Notably, we design a robust MA removal method to mitigate the impact of MA. Furthermore, we explore the uniqueness of the human cardiac system and extract the fiducial features in the PPG measurements to train the gradient boosting tree (GBT) classifier, which can effectively differentiate users continuously using low training effort. In particular, we build the prototype of our system using a commodity smartwatch and a WebSocket server running on a laptop for CA. In order to demonstrate the practical use of our system, we will demo our prototype under different scenarios (i.e., static and moving) to show it can effectively detect MA caused by daily activities and achieve a high authentication success rate.",class:"inproceedings{zhao2019toward,<br>  title={Toward Continuous User Authentication Using PPG in Commodity Wrist-Worn Wearables},<br>  author={Zhao, Tianming and Wang, Yan and Liu, Jian and Chen, Yingying},<br>  booktitle={The 25th Annual International Conference on Mobile Computing and Networking},<br>  pages={1--3},<br>  year={2019}<br>}"},{label:"Poster",year:"2019",topic:"Others",photo:"{{ site.baseurl }}/img/publications/mobicom2019.png",pubname:"ACM MobiCom 2019",authors:"Hongbo Liu, Zhihua Li, Yucheng Xie, Ruizhe Jiang, Yan Wang, Xiaonan Guo, Yingying Chen,",src:"https://dl.acm.org/doi/abs/10.1145/3300061.3343403",name:"Poster: Video Chat Scam Detection Leveraging Screen Light Reflection",public:"Proceedings of the 25th Annual International Conference on Mobile Computing and Networking (MobiCom 2019), Poster Session, Los Cabos, Mexico, October 2019.",acceptance:"",introduction:"The rapid advancement of social media and communication technology enables video chat to become an important and convenient way of daily communication. However, such convenience also makes personal video clips easily obtained and exploited by malicious users who launch scam attacks. Existing studies only deal with the attacks that use fabricated facial masks, while the liveness detection that targets the playback attacks using a virtual camera is still elusive. In this work, we develop a novel video chat liveness detection system, which can track the weak light changes reflected off the skin of a human face leveraging chromatic eigenspace differences. We design an inconspicuous challenge frame with minimal intervention to the video chat and develop a robust anomaly frame detector to verify the liveness of remote user in a video chat session. Furthermore, we propose a resilient defense strategy to defeat both naive and intelligent playback attacks leveraging spatial and temporal verification. The evaluation results show that our system can achieve accurate and robust liveness detection with the accuracy and false detection rate as high as 97.7% (94.8%) and 1% (1.6%) on smartphones (laptops), respectively.",class:"inproceedings{liu2019poster,<br>  title={Poster: Video Chat Scam Detection Leveraging Screen Light Reflection},<br>  author={Liu, Hongbo and Li, Zhihua and Xie, Yucheng and Jiang, Ruizhe and Wang, Yan and Guo, Xiaonan and Chen, Yingying},<br>  booktitle={The 25th Annual International Conference on Mobile Computing and Networking},<br>  pages={1--3},<br>  year={2019}<br>}"},{label:"Poster",year:"before",topic:"Others",photo:"{{ site.baseurl }}/img/publications/mobicom2018.png",pubname:"ACM Mobicom 2018",authors:"Jian Liu, Yudi Dong, Yingying Chen, Yan Wang, Tianming Zhao,",src:"https://dl.acm.org/doi/abs/10.1145/3241539.3267743",name:"Poster: Leveraging Breathing for Continuous User Authentication",public:"Proceedings of the 24th Annual International Conference on Mobile Computing and Networking (MobiCom 2018), Poster Session, New Delhi, India, October 2018.",acceptance:"",introduction:"This work proposes a continuous user verification system based on unique human respiratory-biometric characteristics extracted from the off-the-shelf WiFi signals. Our system innovatively re-uses widely available WiFi signals to capture the unique physiological characteristics rooted in respiratory motions for continuous authentication. Different from existing continuous authentication approaches having limited applicable scenarios due to their dependence on restricted user behaviors (e.g., keystrokes and gaits) or dedicated sensing infrastructures, our approach can be easily integrated into any existing WiFi infrastructure to provide non-invasive continuous authentication independent of user behaviors. Specifically, we extract representative features leveraging waveform morphology analysis and fuzzy wavelet transformation of respiration signals derived from the readily available channel state information (CSI) of WiFi. A respiration-based user authentication scheme is developed to accurately identify users and reject spoofers. Extensive experiments involving 20 subjects demonstrate that the proposed system can achieve a high authentication success rate of over 93% and robustly defend against various types of attacks.",class:"inproceedings{liu2018leveraging,<br>  title={Leveraging breathing for continuous user authentication},<br>  author={Liu, Jian and Dong, Yudi and Chen, Yingying and Wang, Yan and Zhao, Tianming},<br>  booktitle={Proceedings of the 24th Annual International Conference on Mobile Computing and Networking},<br>  pages={786--788},<br>  year={2018}<br>}"},{label:"Poster",year:"before",topic:"Wearables",photo:"{{ site.baseurl }}/img/publications/mobicom2018.png",pubname:"ACM Mobicom 2018",authors:"Chen Wang, Jian Liu, Xiaonan Guo, Yan Wang, Yingying Chen,",src:"https://dl.acm.org/doi/abs/10.1145/3241539.3267742",name:"Poster: Inferring Mobile Payment Passcodes Leveraging Wearable Devices",public:"Proceedings of the 24th Annual International Conference on Mobile Computing and Networking (MobiCom 2018), Poster Session, New Delhi, India, October 2018.",acceptance:"",introduction:"Mobile payment has drawn considerable attention due to its convenience of paying via personal mobile devices at anytime and anywhere, and passcodes (i.e., PINs) are the first choice of most consumers to authorize the payment. This work demonstrates a serious security breach and aims to raise the awareness of the public that the passcodes for authorizing transactions in mobile payments can be leaked by exploiting the embedded sensors in wearable devices (e.g., smartwatches). We present a passcode inference system, which examines to what extent the user's PIN during mobile payment could be revealed from a single wrist-worn wearable device under different input scenarios involving either two hands or a single hand. Extensive experiments with 15 volunteers demonstrate that an adversary is able to recover a user's PIN with high success rate within 5 tries under various input scenarios.",class:"inproceedings{wang2018inferring,<br>  title={Inferring Mobile Payment Passcodes Leveraging Wearable Devices},<br>  author={Wang, Chen and Liu, Jian and Guo, Xiaonan and Wang, Yan and Chen, Yingying},<br>  booktitle={Proceedings of the 24th Annual International Conference on Mobile Computing and Networking},<br>  pages={789--791},<br>  year={2018}<br>}"},{label:"Poster",year:"before",topic:"Others",photo:"{{ site.baseurl }}/img/publications/mobicom2018.png",pubname:"ACM Mobicom 2018",authors:"Fatemeh Tahmasbi, Yan Wang, Yingying Chen, Marco Gruteser,",src:"https://dl.acm.org/doi/abs/10.1145/3241539.3267769",name:"Poster: Your Phone Tells Us The Truth: Driver Identification Using Smartphone on One Turn",public:"Proceedings of the 24th Annual International Conference on Mobile Computing and Networking (MobiCom 2018), Poster Session, New Delhi, India, October 2018.",acceptance:"",introduction:"Due to the extensive use of smart devices using them to study the driving behaviors has attracted a lot of researchers. This work demonstrates the problem of identifying drivers based on their driving style using smart phones. For this purpose the turns done by the drivers are being studied. Different sensors are embedded in the smart phones which are being used in order to extract some features to distinguish different drivers. Experiments are being done with four drivers and the results show that our system can distinguish them with high accuracy of 92% using only one turn.",class:"inproceedings{tahmasbi2018your,<br>  title={Your phone tells us the truth: Driver identification using smartphone on one turn},<br>  author={Tahmasbi, Fatemeh and Wang, Yan and Chen, Yingying and Gruteser, Marco},<br>  booktitle={Proceedings of the 24th Annual International Conference on Mobile Computing and Networking},<br>  pages={762--764},<br>  year={2018}<br>}"},{label:"Poster",year:"before",topic:"Wearables",photo:"{{ site.baseurl }}/img/publications/mobicom2018.png",pubname:"ACM Mobicom 2018",authors:"Tianming Zhao, Yan Wang, Jian Liu, Yingying Chen,",src:"https://dl.acm.org/doi/abs/10.1145/3241539.3267748",name:"Poster: Your Heart Won't Lie: PPG-based Continuous Authentication on Wrist-worn Wearable Devices",public:"Proceedings of the 24th Annual International Conference on Mobile Computing and Networking (MobiCom 2018), Poster Session, New Delhi, India, October 2018.",acceptance:"",introduction:"This paper presents a photoplethysmography (PPG)-based continuous user authentication (CA) system, which especially leverages the PPG sensors in wrist-worn wearable devices to identify users. We explore the uniqueness of the human cardiac system captured by the PPG sensing technology. Existing CA systems require either the dedicated sensing hardware or specific gestures, whereas our system does not require any users' interactions but only the wearable device, which has already been pervasively equipped with PPG sensors. Notably, we design a robust motion artifacts (MA) removal method to mitigate the impact of MA from wrist movements. Additionally, we explore the characteristic fiducial features from PPG measurements to efficiently distinguish the human cardiac system. Furthermore, we develop a cardiac-based classifier for user identification using the Gradient Boosting Tree (GBT). Experiments with the prototype of the wrist-worn PPG sensing platform and 10 participants in different scenarios demonstrate that our system can effectively remove MA and achieve a high average authentication success rate over 90%.",class:"inproceedings{zhao2018your,<br>  title={Your heart won't lie: PPG-based continuous authentication on wrist-worn wearable devices},<br>  author={Zhao, Tianming and Wang, Yan and Liu, Jian and Chen, Yingying},<br>  booktitle={Proceedings of the 24th Annual International Conference on Mobile Computing and Networking},<br>  pages={783--785},<br>  year={2018}<br>}"},{label:"Poster",year:"before",topic:"Others",photo:"{{ site.baseurl }}/img/publications/default.png",pubname:"IEEE S&P 2014",authors:"Yan Wang, Yingying Chen, Fan Ye, Jie Yang, Hongbo Liu,",src:"",name:"A Study of Smartphone User Privacy from the Advertiser's Perspective",public:"35th IEEE Symposium on Security and Privacy (IEEE S&P), Poster Session, San Jose, CA, May, 2014.",acceptance:"",introduction:"",class:""},{label:"Poster",year:"before",topic:"WiFi",photo:"{{ site.baseurl }}/img/publications/mobicom2013.png",pubname:"ACM Mobicom 2013",authors:"Yan Wang, Jie Yang, Hongbo Liu, Yingying Chen, Marco Gruteser, Richard P. Martin,",src:"https://dl.acm.org/doi/abs/10.1145/2500423.2504584?casa_token=bvvCezQ1oj4AAAAA:qz8jEumPUKgteYaRTrytTslnr5Bq1R_niIak7xeyeMTAsfoGGtkGEPbfJjDwUwR-C1MaMovnJYC-",name:"Measuring Human Queues Using WiFi Signals",public:"Proceedings of ACM Conference on Mobile Computing and Networking (ACM MobiCom), Pages 235-238, Poster Session, Miami, Florida, 2013.",acceptance:"Winner of Student Research Competition",introduction:"We investigate using smartphone WiFi signals to track human queues, which are common in many business areas such as retail stores, airports, and theme parks. Real-time monitoring of such queues would enable a wealth of new applications, such as bottleneck analysis, shift assignments, and dynamic workflow scheduling. We take a minimum infrastructure approach and thus utilize a single monitor placed close to the service area along with transmitting phones. Our strategy extracts unique features embedded in the signal traces to infer the critical time points when a person reaches the head of the queue and finishes service, and from these inferences we derive a person's waiting and service times. We develop a feature driven approach in our system. Extensive experiments conducted both in the laboratory demonstrate that our system is robust to queues with different waiting time. We show that in spite of noisy signal readings, our methods can measure important time periods in queue (e.g., service and waiting times) to within a 10 second resolution.",class:"inproceedings{wang2013measuring,<br>  title={Measuring human queues using WiFi signals},<br>  author={Wang, Yan and Yang, Jie and Liu, Hongbo and Chen, Yingying and Gruteser, Marco and Martin, Richard P},<br>  booktitle={Proceedings of the 19th annual international conference on Mobile computing \& networking},<br>  pages={235--238},<br>  year={2013}<br>}"},{label:"Journal",year:"2022",topic:"Mobile",photo:"{{ site.baseurl }}/img/publications/default.png",pubname:"Proceedings of the IEEE",authors:"Tianming Zhao, Yucheng Xie, Yan Wang, Jerry Cheng, Xiaonan Guo, Bin Hu, Yingying Chen",src:"https://ieeexplore.ieee.org/abstract/document/9733049?casa_token=gRngdxIXuJ0AAAAA:Q9BdT0t8NjrDsqSOXL-bXLxbGjAKue422hiQ4keOgeahD6v0amDqmYhyRaA4Q88OpTEQnQzjnA",name:"A Survey of Deep Learning on Mobile Devices: Applications, Optimizations, Challenges, and Research Opportunities",public:"Proceedings of the IEEE, 2022.",acceptance:"",introduction:"Deep learning (DL) has demonstrated great performance in various applications on powerful computers and servers. Recently, with the advancement of more powerful mobile devices (e.g., smartphones and touch pads), researchers are seeking DL solutions that could be deployed on mobile devices. Compared to traditional DL solutions using cloud servers, deploying DL on mobile devices have unique advantages in data privacy, communication overhead, and system cost. This article provides a comprehensive survey for the current studies of adopting and deploying DL on mobile devices. Specifically, we summarize and compare the state-of-the-art DL techniques on mobile devices in various application domains involving vision, speech/speaker recognition, human activity recognition, transportation mode detection, and security. We generalize an optimization pipeline for bringing DL to mobile devices, including model-oriented optimization mechanisms (e.g., pruning and quantization) and nonmodel-oriented optimization mechanisms (e.g., software accelerator and hardware design). Moreover, we summarize popular DL libraries regarding their support to state-of-the-art models (software) and processors (hardware). Based on our summarization, we further provide insights into potential research opportunities for developing DL for mobile devices.",class:"article{zhao2022survey,<br>  title={A Survey of Deep Learning on Mobile Devices: Applications, Optimizations, Challenges, and Research Opportunities},<br>  author={Zhao, Tianming and Xie, Yucheng and Wang, Yan and Cheng, Jerry and Guo, Xiaonan and Hu, Bin and Chen, Yingying},<br>  journal={Proceedings of the IEEE},<br>  volume={110},<br>  number={3},<br>  pages={334--354},<br>  year={2022},<br>  publisher={IEEE}<br>}"},{label:"Journal",year:"2021",topic:"Wearables",photo:"{{ site.baseurl }}/img/publications/IoT2021.png",pubname:"IEEE IoT",authors:"Tianming Zhao, Yan Wang, Jian Liu, Jerry Cheng, Yingying Chen, Jiadi Yu",src:"https://ieeexplore.ieee.org/abstract/document/9615379?casa_token=0pNwYcfTbFAAAAAA:Ry3Sv4B6lAz_FDCFSWjttmGxFUg1zDGkZbfQJBqiSRPBv-M8oN-Y3N7cgYS6JWZHRmpC0n_8MA",name:"Robust Continuous Authentication Using Cardiac Biometrics from Wrist-worn Wearables",public:"IEEE Internet of Things Journal (IEEE IoT), Early Access, DOI:10.1109/JIOT.2021.3128290, 2021.",acceptance:"",introduction:"Traditional one-time user authentication is vulnerable to attacks when an adversary can obtain unauthorized privileges after a user’s initial login. Continuous user authentication (CA) has recently shown its great potential by enabling seamless user authentication with few users’ participation. We devise a low-cost system that can exploit users’ pulsatile signals from photoplethysmography (PPG) sensors in commodity wearable devices to perform CA. Our system requires zero user effort and applies to practical scenarios that have nonclinical PPG measurements with human motion artifacts (MAs). We explore the uniqueness of the human cardiac system and develop adaptive MA filtering methods to mitigate the impacts of transient and continuous activities from daily life. Furthermore, we identify general fiducial features and develop an adaptive classifier that can authenticate users continuously based on their cardiac characteristics with little additional training effort. Experiments with our wrist-worn PPG sensing platform on 20 participants under practical scenarios demonstrate that our system can achieve a high CA accuracy of over 90% and a low false detection rate of 4% in detecting random attacks. We show that our MA mitigation approaches can improve the CA accuracy by around 39% under both transient and continuous daily activity scenarios.",class:"article{zhao2021robust,<br>  title={Robust continuous authentication using cardiac biometrics from wrist-worn wearables},<br>  author={Zhao, Tianming and Wang, Yan and Liu, Jian and Cheng, Jerry and Chen, Yingying and Yu, Jiadi},<br>  journal={IEEE Internet of Things Journal},<br>  year={2021},<br>  publisher={IEEE}<br>}"},{label:"Journal",year:"2021",topic:"mmWave",photo:"{{ site.baseurl }}/img/publications/Elseview.png",pubname:"Elsevier Smart Health",authors:"Cong Shi, Li Lu, Jian Liu, Yan Wang, Yingying Chen, Jiadi Yu",src:"https://www.sciencedirect.com/science/article/pii/S2352648321000489?casa_token=ULTgqqZz61IAAAAA:pV_N5nwXFz-l2Bq4AneSw5EHYmVcEL1R-ZiMGWrqUKpCrO3QH4ug2hivvXdEUcQkvcu8ztFYqQ",name:"mPose: Environment- and Subject-Agnostic 3D Skeleton Posture Reconstruction Leveraging a Single mmWave Device",public:"Elsevier Smart Health, 2021. (To appear)",acceptance:"",introduction:"Human skeleton posture reconstruction is an essential component for human–computer interactions (HCI) in various application domains. Traditional approaches usually rely on either cameras or on-body sensors, which induce privacy concerns or inconvenient practical setups. To address these practical concerns, this paper proposes a low-cost contactless skeleton posture reconstruction system, mPose, which can reconstruct a user’s 3D skeleton postures using a single mmWave device. mPose does not require the user to wear any sensors and can enable a broad range of emerging mobile applications (e.g., VR gaming and pervasive user input) via mmWave-5G ready Internet of Things (IoT) devices. Particularly, the system extracts multi-dimensional spatial information from mmWave signals which characterizes the skeleton postures in a 3D space. To mitigate the impacts of environmental changes, mPose dynamically detects the user location and extracts spatial features from the mmWave signals reflected only from the user. Furthermore, we develop a deep regression method with a domain discriminator to learn a mapping between the spatial features and the joint coordinates of human body while removing subject-specific characteristics, realizing robust posture reconstruction across users. Extensive experiments, involving 17 representative body postures, 7 subjects, and 3 indoor environments, show that mPose outperforms contemporary state-of-the-art RF-based solutions with a lower average joint error of only 30 mm, while achieving transferability across environments and subjects at the same time.",class:"article{shi2022mpose,<br>  title={mPose: Environment-and subject-agnostic 3D skeleton posture reconstruction leveraging a single mmWave device},<br>  author={Shi, Cong and Lu, Li and Liu, Jian and Wang, Yan and Chen, Yingying and Yu, Jiadi},<br>  journal={Smart Health},<br>  volume={23},<br>  pages={100228},<br>  year={2022},<br>  publisher={Elsevier}<br>}"},{label:"Journal",year:"2021",topic:"Wearables",photo:"{{ site.baseurl }}/img/publications/default.png",pubname:"IEEE S&P",authors:"Cong Shi, Yan Wang, Yingying Chen, Nitesh Saxena",src:"https://ieeexplore.ieee.org/abstract/document/9440195?casa_token=W0S-UxGtTXoAAAAA:jzxVyR3B-WPTzOyjX5Stv9IKlbdaAFb7JvH2omHa0XHvnV3fB4NJeOAcmLPgFN8GWXcaK_0NJw",name:"Authentication of Voice Commands on Voice Assistance Systems Leveraging Vibrations on Wearables",public:"IEEE Security & Privacy Magazine (IEEE S&P), 2021. (To appear)",acceptance:"",introduction:"Voice assistant systems are convenient, but attackers can mimic users’ voices to access them and steal private information. We develop an authentication system that defends against acoustic attacks by using unique characteristics captured by the accelerometers in wearable devices.",class:"article{shi2021authentication,<br>  title={Authentication of voice commands by leveraging vibrations in wearables},<br>  author={Shi, Cong and Wang, Yan and Chen, Yingying Jennifer and Saxena, Nitesh},<br>  journal={IEEE Security \& Privacy},<br>  volume={19},<br>  number={6},<br>  pages={83--92},<br>  year={2021},<br>  publisher={IEEE}<br>}"},{label:"Journal",year:"2020",topic:"Acoustic",photo:"{{ site.baseurl }}/img/publications/amwut.png",pubname:"ACM AMWUT",authors:"Li Lu, Jiadi Yu, Yingying Chen, Yan Wang, Yanmin Zhu",src:"https://dl.acm.org/doi/abs/10.1145/3397320?casa_token=QVkvv1iztoQAAAAA:us3EPL6mFz9VJ1_vCvmC9Oxml8tsbgnbR0R8Iw6RkDoVFc3j3X-HASN8_NeSk5ikgZEGtUMWwemx",name:"VocalLock: Sensing Vocal Tract for Passphrase-Independent User Authentication Leveraging Acoustic Signals on Smartphones",public:"Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies (ACM IMWUT), Volume 4, Issue 2, No. 51, Pages 1 - 24, DOI: 10.1145/3397320, 2020. (Presented at UbiComp 2020).",acceptance:"",introduction:"",class:"article{lu2020vocallock,<br>  title={Vocallock: Sensing vocal tract for passphrase-independent user authentication leveraging acoustic signals on smartphones},<br>  author={Lu, Li and Yu, Jiadi and Chen, Yingying and Wang, Yan},<br>  journal={Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},<br>  volume={4},<br>  number={2},<br>  pages={1--24},<br>  year={2020},<br>  publisher={ACM New York, NY, USA}<br>}"},{label:"Journal",year:"2020",topic:"Mobile",photo:"{{ site.baseurl }}/img/publications/computer.png",pubname:"Computer Networks",authors:"Chen Wang, Yan Wang, Yingying Chen, Hongbo Liu, Jian Liu",src:"",name:"User Authentication on Mobile Devices: Approaches, Threats and Trends",public:"Computer Networks, Volume 170, Page 107118, DOI: 10.1016/j.comnet.2020.107118, 2020.",acceptance:"",introduction:"",class:""},{label:"Journal",year:"2019",topic:"Others",photo:"{{ site.baseurl }}/img/publications/computer.png",pubname:"IEEE Communications Surveys and Tutorials",authors:"Jian Liu, Hongbo Liu, Yingying Chen, Yan Wang, Chen Wang",src:"",name:"Wireless Sensing for Human Activity: A Survey",public:"IEEE Communications Surveys and Tutorials, Volume 22, Issue 3, Pages 1629 - 1645, DOI: 10.1109/COMST.2019.2934489, 2019.",acceptance:"",introduction:"",class:""},{label:"Journal",year:"2019",topic:"Wearables",photo:"{{ site.baseurl }}/img/publications/tmc2019.png",pubname:"IEEE TMC",authors:"Tianming Zhao, Jian Liu, Yan Wang, Hongbo Liu, Yingying Chen",src:"",name:"Towards Low-cost Sign Language Gesture Recognition Leveraging Wearables",public:"IEEE Transactions on Mobile Computing (IEEE TMC), Volume: 20, Issue: 4, DOI: 10.1109/TMC.2019.2962760, 2019.",acceptance:"",introduction:"",class:""},{label:"Journal",year:"2019",topic:"Others",photo:"{{ site.baseurl }}/img/publications/pmc2019.jpg",pubname:"Elseview PMC",authors:"Yan Wang, Yingying Chen, Fan Ye, Hongbo Liu, Jie Yang",src:"https://www.sciencedirect.com/science/article/pii/S1574119218300373?casa_token=BQDHFuzLLpEAAAAA:32nXSpjRWTIe7kbmdgiffVGrBLUVh3FvxMAc5ZF6SxfF7UQ9Nwq0P6xEQH2YzKeJ-JmdVUZKTg",name:"Implications of Smartphone User Privacy Leakage from the Advertiser's Perspective",public:"Pervasive and Mobile Computing (Elsevier PMC), Volume 53, Pages 13-32, DOI: 10.1016/j.pmcj.2018.12.006, 2019.",acceptance:"",introduction:"Many smartphone apps routinely gather various private user data and send them to advertisers. Despite recent study on protection mechanisms and analysis on apps’ behavior, the understanding of the consequences of such privacy losses remains limited. In this paper, we investigate how much an advertiser can infer about users’ social and community relationships. After one month’s user study involving about 190 most popular Android apps, we find that an advertiser can infer 90% of the social relationships. We further propose a privacy leakage inference framework and use real mobility traces and Foursquare data to quantify the consequences of privacy leakage. We find that achieving 90% inference accuracy of the social and community relationships requires merely 3 weeks’ user data. Finally, we present a real-time privacy leakage visualization tool that captures and displays the spatial–temporal characteristics of the leakages. The discoveries underscore the importance of early adoption of privacy protection mechanisms.",class:"article{wang2019implications,<br>  title={Implications of smartphone user privacy leakage from the advertiser’s perspective},<br>  author={Wang, Yan and Chen, Yingying and Ye, Fan and Liu, Hongbo and Yang, Jie},<br>  journal={Pervasive and Mobile Computing},<br>  volume={53},<br>  pages={13--32},<br>  year={2019},<br>  publisher={Elsevier}<br>}"},{label:"Journal",year:"before",topic:"WiFi",photo:"{{ site.baseurl }}/img/publications/default.png",pubname:"IEEE IoT",authors:"Jian Liu, Yingying Chen, Yan Wang, Xu Chen, Jerry Cheng, Jie Yang",src:"",name:"Monitoring Vital Signs and Postures During Sleep Using WiFi Signals",public:"IEEE Internet of Things Journal (IEEE IoT), Volume 5, Issue 3, Pages 2071-2084, 2018.",acceptance:"",introduction:"",class:""},{label:"Journal",year:"before",topic:"Wearables",photo:"{{ site.baseurl }}/img/publications/tmc2019.png",pubname:"IEEE TMC",authors:"Chen Wang, Xiaonan Guo, Yingying Chen, Yan Wang, Bo Liu",src:"",name:"Personal PIN Leakage from Wearable Devices",public:"IEEE Transactions on Mobile Computing (IEEE TMC), Volume 17, Issue 3, Pages 646-660, 2018.",acceptance:"",introduction:"",class:""},{label:"Journal",year:"before",topic:"Others",photo:"{{ site.baseurl }}/img/publications/tmc2019.png",pubname:"IEEE TMC",authors:"Hongbo Liu, Yan Wang, Jian Liu, Jie Yang, Yingying Chen, H. Vincent Poor",src:"",name:"Authenticating Users through Fine-grained Channel Information",public:"IEEE Transactions on Mobile Computing (IEEE TMC), Volume 17, Issue 2, Pages 251-264, 2018.",acceptance:"",introduction:"",class:""},{label:"Journal",year:"before",topic:"Others",photo:"{{ site.baseurl }}/img/publications/tmc2019.png",pubname:"IEEE TMC",authors:"Yan Wang, Yingying Chen, Jie Yang, Luyang Liu, Marco Gruteser, Richard P. Martin, Hongbo Liu",src:"https://ieeexplore.ieee.org/abstract/document/7279177?casa_token=I07r3Z1nI5oAAAAA:asMQhATOXxXsIjjJc_yXMLIVnq1hGs8qCEngucxrtXYdg4HwjzC7ie6jfc2i5XrxDWauxOrPGA",name:"Determining Driver Phone Use by Exploiting Smartphone Integrated Sensors",public:"IEEE Transactions on Mobile Computing (IEEE TMC), Volume 15, Issue 8, Pages 1965-1981, 2016.",acceptance:"",introduction:"This paper utilizes smartphone sensing of vehicle dynamics to determine driver phone use, which can facilitate many traffic safety applications. Our system uses embedded sensors in smartphones, i.e., accelerometers and gyroscopes, to capture differences in centripetal acceleration due to vehicle dynamics. These differences combined with angular speed can determine whether the phone is on the left or right side of the vehicle. Our low infrastructure approach is flexible with different turn sizes and driving speeds. Extensive experiments conducted with two vehicles in two different cities demonstrate that our system is robust to real driving environments. Despite noisy sensor readings from smartphones, our approach can achieve a classification accuracy of over 90 percent with a false positive rate of a few percent. We also find that by combining sensing results in a few turns, we can achieve better accuracy (e.g., 95 percent) with a lower false positive rate. In addition, we seek to exploit the electromagnetic field measurement inside a vehicle to complement vehicle dynamics for driver phone sensing under the scenarios when little vehicle dynamics is present, for example, driving straight on highways or standing at roadsides.",class:"article{wang2015determining,<br>  title={Determining driver phone use by exploiting smartphone integrated sensors},<br>  author={Wang, Yan and Chen, Yingying Jennifer and Yang, Jie and Gruteser, Marco and Martin, Richard P and Liu, Hongbo and Liu, Luyang and Karatas, Cagdas},<br>  journal={IEEE Transactions on Mobile Computing},<br>  volume={15},<br>  number={8},<br>  pages={1965--1981},<br>  year={2015},<br>  publisher={IEEE}<br>}"},{label:"Journal",year:"before",topic:"Others",photo:"{{ site.baseurl }}/img/publications/tmc2019.png",pubname:"IEEE TMC",authors:"Hongbo Liu, Jie Yang, Yan Wang, Yingying Chen, and C. Emre Koksal",src:"",name:"Group Secret Key Generation via Received Signal Strength: Protocols, Achievable Rates, and Implementation",public:"IEEE Transactions on Mobile Computing (IEEE TMC), Volume 13, Issue 12, Pages 2820-2835, 2014.",acceptance:"",introduction:"",class:""},{label:"Journal",year:"before",topic:"Mobile",photo:"{{ site.baseurl }}/img/publications/default.png",pubname:"IEEE TWC",authors:"Yan Wang, Mooi Choo Chuah and Yingying Chen",src:"https://ieeexplore.ieee.org/abstract/document/6684544?casa_token=vBbDTQkvUz0AAAAA:nAZ2_jQbNJh_ihQiX6RfXyWTZUyEJh2Y99FbHdBGg5VDqXmtAzSN096U07IQf02ez5cCfx_Yfg",name:"Incentive Based Data Sharing in Delay Tolerant Mobile Networks",public:"IEEE Transactions on Wireless Communications (IEEE TWC), Volume.3, No.1, Pages.370-381, 2014.",acceptance:"",introduction:"Mobile wireless devices play important roles in our daily life, e.g., users often use such devices to take pictures and share with friends via opportunistic peer-to-peer links, which however are intermittent in nature, and hence require the store-and-forward feature proposed in Delay Tolerant Networks to provide useful data sharing opportunities. Moreover, mobile devices may not be willing to forward data items to other devices due to the limited resources. Hence, effective data dissemination schemes need to be designed to encourage nodes to collaboratively share data. We propose a Multi-Receiver Incentive-Based Dissemination (MuRIS) scheme that allows nodes to cooperatively deliver information of interest to one another via chosen paths utilizing few transmissions. Our scheme exploits local historical paths and users' interests information maintained by each node. In addition, the charge and rewarding functions incorporated within our scheme stimulate cooperation among nodes such that the nodes have no incentive to launch edge insertion attacks. Furthermore, our charge and rewarding functions are designed such that the chosen delivery paths mimic efficient multicast tree that results in fewer delivery hops. Extensive simulation studies using real human contact-based mobility traces show that our scheme outperforms existing methods in terms of delivery ratio and transmission efficiency.",class:"article{wang2013incentive,<br>  title={Incentive based data sharing in delay tolerant mobile networks},<br>  author={Wang, Yan and Chuah, Mooi-Choo and Chen, Yingying},<br>  journal={IEEE Transactions on wireless communications},<br>  volume={13},<br>  number={1},<br>  pages={370--381},<br>  year={2013},<br>  publisher={IEEE}<br>}"},{label:"Journal",year:"before",topic:"WiFi",photo:"{{ site.baseurl }}/img/publications/pervasive.png",pubname:"IEEE Pervasive Computing Magazine",authors:"Yan Wang, Yingying Chen, and Richard P. Martin",src:"",name:"Leveraging Wi-Fi Signals to Monitor Human Queues",public:"IEEE Pervasive Computing Magazine, Volume 13, No. 2, Pages 14-17, April-June 2014.",acceptance:"",introduction:"",class:""},]

  var nav=document.getElementsByClassName("label")[0];
  var label = nav.getElementsByTagName("li");
  var pub = document.getElementsByClassName("pub-list")[0];
  var syear=document.getElementById("select-year");
  var stopic=document.getElementById("select-topic");
  var year=syear[0];
  var topic=stopic[0];

  var state={
    text:'',
    category:'All'
  }
  function renderPage(data,state_category) {
    var count=0

    pub.innerHTML = "";
    data.forEach(function (ele, index, self) {
        if (state_category=='All' || state_category==ele.label){
        //遍历数组里面的东西，取其中数据构建html结构，
        var format="odd";
        if(count%2==1){
          format="even"
        }
        pub.innerHTML+='<div class="publications">         <div class="publication card '+format+'" id="'+ele.label+count+'">         <div class="row no-gutters">           <div class="col-auto d-none d-md-block p-2">      <a href="'+ele.photo+'">       <img class="thumb" src="'+ele.photo+'" loading="lazy" /></a>          </div>           <div class="col pl-2">             <div class="card-block py-2"><div class="bib"><div class="pub-p" style="margin-top:5px"><button class="btn" style="background-color:rgb(161, 10, 39);color: azure;font-family:"Segoe UI", Tahoma, Geneva, Verdana, sans-serif;">'+ele.pubname+'</button>&nbsp'+ele.authors+'</div> <em><a href="'+ele.src+'" target="_blank" style="font-size=18px">'+ele.name+'</a></em><div class="pub-p">'+ele.public+'<span style="color: #933;font-weight:600"> '+ele.acceptance+'</span></div></div>            </div>          </div>          <div class="col-auto d-none d-md-block">            <div class="btn-group-vertical" role="group">              <a class="btn btn-link p-1" href="#" data-toggle="modal" data-target="#'+ele.label+count+'-fulltext">              <svg xmlns="http://www.w3.org/2000/svg" height="36" viewBox="0 0 36 36" width="36" fill="currentColor"><path d="M0 0h36v36H0z" fill="none"/><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76 0-5 2.36-5 5s2.36 5 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76 0 5-2.36 5-5s-2.36-5-5-5z"/></svg></a>              <a class="btn btn-link p-1" href="#" data-toggle="modal" data-target="#'+ele.label+count+'-abstract">              <svg xmlns="http://www.w3.org/2000/svg" height="36" viewBox="0 0 36 36" width="36" fill="currentColor"><path d="M0 0h36v36H0z" fill="none"/><path d="M14 17H4v2h10v-2zm6-8H4v2h16V9zM4 15h16v-2H4v2zM4 5v2h16V5H4z"/></svg></a>              <a class="btn btn-link p-1" href="#" data-toggle="modal" data-target="#'+ele.label+count+'-bibtex">              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 36 36" fill="currentColor" width="30px" height="30px"><path d="M0 0h36v36H0z" fill="none"/><path d="M6 17h3l2-4V7H5v6h3zm8 0h3l2-4V7h-6v6h3z"/></svg></a>            </div>          </div>        </div>        </div>    </div>    <div class="modal" id="'+ele.label+count+'-fulltext" tabindex="-1" data-focus="false">        <div class="modal-dialog modal-lg">          <div class="modal-content">            <div class="modal-header">              <h5 class="modal-title">Fulltext Options</h5>              <button type="button" class="close" data-dismiss="modal" aria-label="Close">                <span aria-hidden="true">&times;</span>              </button>            </div>            <div class="modal-body">              <div class="list-group list-group-flush"><a class="list-group-item list-group-item-action pub-toast" href="'+ele.src+'">'+ele.src.substring(0,80)+'</a></div>            </div>            <div class="modal-footer">              <button type="button" class="btn btn-secondary" data-dismiss="modal">Close</button>            </div>          </div>        </div>      </div>    <div class="modal" id="'+ele.label+count+'-abstract" tabindex="-1" data-focus="false">        <div class="modal-dialog modal-lg">          <div class="modal-content">            <div class="modal-header">              <h5 class="modal-title">Universal targeted attacks against mmWave-based human activity recognition system</h5>              <button type="button" class="close" data-dismiss="modal" aria-label="Close">                <span aria-hidden="true">&times;</span>              </button>            </div>            <div class="modal-body pub-toast">                '+ele.introduction+'</div>            <div class="modal-footer">              <button type="button" class="btn btn-secondary" data-dismiss="modal">Close</button>            </div>          </div>        </div>      </div>        <div class="modal" id="'+ele.label+count+'-bibtex" tabindex="-1" data-focus="false">        <div class="modal-dialog modal-lg">          <div class="modal-content">            <div class="modal-header">              <h5 class="modal-title">BibTeX Entry</h5>              <button type="button" class="close" data-dismiss="modal" aria-label="Close">                <span aria-hidden="true">&times;</span>              </button>            </div>            <div class="modal-body pub-toast">              <pre>'+
'@'+ele.class+'<div class="modal-footer">              <button type="button" class="btn btn-secondary" data-dismiss="modal">Close</button>            </div>         </div>        </div>      </div>';
        console.log('True');
                                }
        console.log(state_category);
        count+=1;
     });
}
renderPage(arr, state.category);
var lastDefault = label[0]; //默认性别选项All 
for(var i = 0; i < label.length; i++){
    (function(j){
      label[j].onclick = function(){
        var oldLabel=lastDefault.getElementsByClassName("nav-link")[0];
        var newLabel=label[j].getElementsByClassName("nav-link")[0];
        
        oldLabel.className = "nav-link";// 赋给样式后，取消上一个btn的样式
        newLabel.className = "nav-link active";//点击时，给点击的按钮添加 css样式(default)
        oldLabel.className = "nav-link";// 赋给样式后，取消上一个btn的样式
            lastDefault = label[j];//赋给样式后，此次点击的btn 就成了过去

            state.category = label[j].id;
            console.log(state.category);
            renderPageBySelect(arr,state.category,year.value,topic.value);
            console.log(arr);
            // var newArr = screenSelect(arr, state.category); //筛选性别执行后返回新数组
            // console.log(newArr);
            // renderPage( screenInput(newArr, state.text));//利用新数组再次筛选搜索框，筛选后渲染页面
        }
    })(i)
}

function renderPageBySelect(data,state_category,selected_year,selected_topic) {
  var count=0;

  console.log(data);
  pub.innerHTML = "";
  data.forEach(function (ele, index, self) {
    if (state_category=='All' || state_category==ele.label){
    //遍历数组里面的东西，取其中数据构建html结构，
    if(selected_year=='All'||selected_year=='Year'||selected_year==ele.year){
      if(selected_topic=='All'||selected_topic=='Topic'||selected_topic==ele.topic){
    var format="odd";
    if(count%2==1){
      format="even"
    }
    pub.innerHTML+='<div class="publications">         <div class="publication card '+format+'" id="'+ele.label+count+'">         <div class="row no-gutters">           <div class="col-auto d-none d-md-block p-2">      <a href="'+ele.photo+'">       <img class="thumb" src="'+ele.photo+'" loading="lazy" /></a>          </div>           <div class="col pl-2">             <div class="card-block py-2"><div class="bib"><div class="pub-p" style="margin-top:5px"><button class="btn" style="background-color:rgb(161, 10, 39);color: azure;font-family:"Segoe UI", Tahoma, Geneva, Verdana, sans-serif;">'+ele.pubname+'</button>&nbsp'+ele.authors+'</div> <em><a href="'+ele.src+'" target="_blank" style="font-size=18px"><div class="pub-p">'+ele.name+'</div></a></em><div class="pub-p">'+ele.public+'<span style="color: #933;font-weight:600"> '+ele.acceptance+'</span></div></div>            </div>          </div>          <div class="col-auto d-none d-md-block">            <div class="btn-group-vertical" role="group">              <a class="btn btn-link p-1" href="#" data-toggle="modal" data-target="#'+ele.label+count+'-fulltext">              <svg xmlns="http://www.w3.org/2000/svg" height="36" viewBox="0 0 36 36" width="36" fill="currentColor"><path d="M0 0h36v36H0z" fill="none"/><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76 0-5 2.36-5 5s2.36 5 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76 0 5-2.36 5-5s-2.36-5-5-5z"/></svg></a>              <a class="btn btn-link p-1" href="#" data-toggle="modal" data-target="#'+ele.label+count+'-abstract">              <svg xmlns="http://www.w3.org/2000/svg" height="36" viewBox="0 0 36 36" width="36" fill="currentColor"><path d="M0 0h36v36H0z" fill="none"/><path d="M14 17H4v2h10v-2zm6-8H4v2h16V9zM4 15h16v-2H4v2zM4 5v2h16V5H4z"/></svg></a>              <a class="btn btn-link p-1" href="#" data-toggle="modal" data-target="#'+ele.label+count+'-bibtex">              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 36 36" fill="currentColor" width="30px" height="30px"><path d="M0 0h36v36H0z" fill="none"/><path d="M6 17h3l2-4V7H5v6h3zm8 0h3l2-4V7h-6v6h3z"/></svg></a>            </div>          </div>        </div>        </div>    </div>    <div class="modal" id="'+ele.label+count+'-fulltext" tabindex="-1" data-focus="false">        <div class="modal-dialog modal-lg">          <div class="modal-content">            <div class="modal-header">              <h5 class="modal-title">Fulltext Options</h5>              <button type="button" class="close" data-dismiss="modal" aria-label="Close">                <span aria-hidden="true">&times;</span>              </button>            </div>            <div class="modal-body">              <div class="list-group list-group-flush"><a class="list-group-item list-group-item-action pub-toast" href="'+ele.src+'">'+ele.src.substring(0,80)+'</a></div>            </div>            <div class="modal-footer">              <button type="button" class="btn btn-secondary" data-dismiss="modal">Close</button>            </div>          </div>        </div>      </div>    <div class="modal" id="'+ele.label+count+'-abstract" tabindex="-1" data-focus="false">        <div class="modal-dialog modal-lg">          <div class="modal-content">            <div class="modal-header">              <h5 class="modal-title">Universal targeted attacks against mmWave-based human activity recognition system</h5>              <button type="button" class="close" data-dismiss="modal" aria-label="Close">                <span aria-hidden="true">&times;</span>              </button>            </div>            <div class="modal-body pub-toast">                '+ele.introduction+'</div>            <div class="modal-footer">              <button type="button" class="btn btn-secondary" data-dismiss="modal">Close</button>            </div>          </div>        </div>      </div>        <div class="modal" id="'+ele.label+count+'-bibtex" tabindex="-1" data-focus="false">        <div class="modal-dialog modal-lg">          <div class="modal-content">            <div class="modal-header">              <h5 class="modal-title">BibTeX Entry</h5>              <button type="button" class="close" data-dismiss="modal" aria-label="Close">                <span aria-hidden="true">&times;</span>              </button>            </div>            <div class="modal-body pub-toast">              <pre>'+
'@'+ele.class+'<div class="modal-footer">              <button type="button" class="btn btn-secondary" data-dismiss="modal">Close</button>            </div>         </div>        </div>      </div>';
    console.log('True');
    }
  }
}
    console.log(state_category);
    count+=1;
 });
}

function submit(){

  for(var i=0;i<syear.length;i++){
    var index=syear[i];
    console.log(index);
    if(index.selected){
      year=syear[i];
    }
  }
  for(var i=0;i<stopic.length;i++){
    var index=stopic[i];
    if(index.selected){
      topic=stopic[i];
    }
  }
  console.log(year);
  console.log(year.value);
  renderPageBySelect(arr,state.category,year.value,topic.value);
}

function resetFilters(){
  renderPage(arr,state.category)
}
</script>


<script>

(function () {
  $(".scroll").click(function (event) {
      event.preventDefault();
      $('html,body').animate({
          scrollTop: $(this.hash).offset().top
      }, 1200);
  });
})

window.onscroll = function() {
     scrollFunction()
 };
   
  function scrollFunction() {
    console.log(121);
      if (document.body.scrollTop > 400 || document.documentElement.scrollTop > 400) {
        
    var opacity=0.1+(document.documentElement.scrollTop-400)/2000
        console.log(document.getElementById("top-page").style.display);
          document.getElementById("top-page").style.display = "block";
          document.getElementById("top-page").style.opacity = opacity;
    } else {
      console.log(document.getElementById("top-page").style.display);
        document.getElementById("top-page").style.display = "none";
    }
 }

</script>
 

{% include footer.html %}

{% include scripts.html %}

{% include google-analytics.html %}

</body>

</html>

